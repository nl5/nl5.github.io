WEBVTT
Kind: captions
Language: pt-BR

00:00:00.495 --> 00:00:04.122
Vamos ver um modelo básico
de rede neural artificial,

00:00:04.155 --> 00:00:06.767
em que temos
uma única camada oculta.

00:00:06.800 --> 00:00:10.821
As entradas se conectam
aos neurônios da camada oculta,

00:00:10.854 --> 00:00:15.471
e os neurônios da camada oculta
se conectam aos da camada de saída,

00:00:15.504 --> 00:00:19.544
onde cada neurônio representa
uma única saída.

00:00:19.577 --> 00:00:23.642
Podemos ver este modelo como
uma coleção de funções matemáticas.

00:00:23.675 --> 00:00:25.902
Cada entrada está conectada
matematicamente

00:00:25.935 --> 00:00:27.819
a uma camada oculta
de neurônios

00:00:27.852 --> 00:00:30.759
através de um conjunto de pesos
que precisamos modificar,

00:00:30.792 --> 00:00:34.340
e cada neurônio da camada oculta
está conectado à camada de saída

00:00:34.373 --> 00:00:35.918
de forma similar.

00:00:37.150 --> 00:00:39.859
Não há limite
para o número de entradas,

00:00:39.892 --> 00:00:42.190
número de neurônios ocultos
em uma camada

00:00:42.223 --> 00:00:44.048
e número de saídas,

00:00:44.081 --> 00:00:47.691
assim como não há correlação
entre esses números.

00:00:47.724 --> 00:00:50.367
Então podemos ter
n entradas,

00:00:50.400 --> 00:00:54.649
m neurônios ocultos
e k saídas.

00:00:54.682 --> 00:00:57.372
Com um olhar mais atento
e ainda mais simplista,

00:00:57.405 --> 00:01:01.445
podemos ver que cada entrada
é multiplicada pelo respectivo peso

00:01:01.478 --> 00:01:06.137
e adicionada ao neurônio
da camada seguinte, com um viés.

00:01:06.170 --> 00:01:08.863
O viés é um parâmetro externo
do neurônio

00:01:08.896 --> 00:01:13.265
e pode ser modelado adicionando
uma entrada de valor fixo externa.

00:01:13.298 --> 00:01:16.913
Esta soma inteira costuma passar
por uma função de ativação,

00:01:16.946 --> 00:01:19.813
até chegar à camada seguinte
ou à saída.

00:01:20.702 --> 00:01:22.460
Mas qual é o nosso objetivo?

00:01:22.493 --> 00:01:24.843
Podemos ver o nosso sistema
como uma caixa preta

00:01:24.876 --> 00:01:28.206
que tem n entradas
e k saídas.

00:01:28.239 --> 00:01:31.248
Nosso objetivo é
criar o sistema de tal forma

00:01:31.281 --> 00:01:36.582
que ele nos dê a saída y certa
para uma entrada x específica.

00:01:36.615 --> 00:01:40.956
Nossa tarefa é definir
o que há dentro dessa caixa preta.

00:01:40.989 --> 00:01:44.198
Sabemos que usaremos
redes neurais artificiais

00:01:44.231 --> 00:01:47.036
e temos que treiná-las,
de modo que o nosso sistema

00:01:47.069 --> 00:01:51.325
gere a saída certa
para uma entrada específica.

00:01:51.358 --> 00:01:53.758
Bom, certa
na maioria das vezes.

00:01:54.794 --> 00:01:59.352
No fundo, o que queremos de fato é
encontrar o conjunto de pesos ideal,

00:01:59.385 --> 00:02:02.604
conectando a entrada
à camada oculta,

00:02:02.637 --> 00:02:07.044
e o conjunto de pesos ideal,
conectando a camada oculta à saída.

00:02:07.077 --> 00:02:09.602
Nós nunca obteremos
a estimativa perfeita,

00:02:09.635 --> 00:02:12.898
mas podemos tentar ao máximo
nos aproximar dela.

00:02:12.931 --> 00:02:17.127
Para fazer isso, precisamos iniciar
um processo que você já conhece:

00:02:17.160 --> 00:02:19.338
a fase de treinamento.

00:02:19.671 --> 00:02:21.772
Então vamos analisar
a fase de treinamento,

00:02:21.805 --> 00:02:25.611
na qual obteremos o melhor conjunto
de pesos para o nosso sistema.

00:02:25.644 --> 00:02:28.345
Essa fase inclui
dois passos:

00:02:28.378 --> 00:02:31.776
feedforward
e retropropagação,

00:02:31.809 --> 00:02:34.980
que repetiremos tantas vezes
quanto for necessário,

00:02:35.013 --> 00:02:39.605
até decidirmos que o nosso sistema
é o melhor possível.

00:02:40.304 --> 00:02:45.136
Na etapa de feedforward,
calcularemos a saída do sistema.

00:02:45.169 --> 00:02:49.629
A saída será comparada
à saída certa,

00:02:49.662 --> 00:02:52.901
o que nos dará um palpite
acerca do erro.

00:02:52.934 --> 00:02:55.400
Há algumas maneiras
de identificar o erro.

00:02:55.433 --> 00:02:58.561
Veremos isso matematicamente
daqui a pouco.

00:02:58.594 --> 00:03:00.429
Na etapa de retropropagação,

00:03:00.462 --> 00:03:04.956
mudaremos os pesos
conforme tentamos minimizar o erro

00:03:04.989 --> 00:03:08.462
e iniciaremos de novo
todo o processo de feedforward.

00:03:10.430 --> 00:03:13.092
Nos próximos vídeos,
vamos analisar melhor

00:03:13.125 --> 00:03:18.436
os cálculos matemáticos das etapas
de feedforward e retropropagação.

00:03:18.469 --> 00:03:20.828
Vamos rever
o que você já sabe,

00:03:20.861 --> 00:03:23.833
mas esperamos também aprofundar
seus conhecimentos.

