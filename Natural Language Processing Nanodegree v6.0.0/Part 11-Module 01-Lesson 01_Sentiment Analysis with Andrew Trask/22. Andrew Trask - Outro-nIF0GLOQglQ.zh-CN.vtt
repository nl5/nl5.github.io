WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.060
本课程中 我们处理了六个不同的

00:00:03.060 --> 00:00:05.609
项目 我们首先整理了数据集

00:00:05.609 --> 00:00:07.350
构建了预测理论

00:00:07.350 --> 00:00:09.179
让神经网络可以识别

00:00:09.179 --> 00:00:11.099
输入和输出数据之间的

00:00:11.099 --> 00:00:13.410
相关性 我们一直在

00:00:13.410 --> 00:00:15.179
使用一些简单的基于计数的方法

00:00:15.179 --> 00:00:17.250
验证此理论 并且发现

00:00:17.250 --> 00:00:18.750
我们能够识别与输出数据具有

00:00:18.750 --> 00:00:20.789
正相关和负相关性的单词

00:00:20.789 --> 00:00:23.220
但是 当我们用这些数据

00:00:23.220 --> 00:00:25.470
训练第一个神经网络时 它只能

00:00:25.470 --> 00:00:27.090
勉强找到相关性

00:00:27.090 --> 00:00:30.539
艰难地绕过噪音 所以

00:00:30.539 --> 00:00:32.488
接下来 我们做的就是

00:00:32.488 --> 00:00:33.930
增加信号量 减少噪音量

00:00:33.930 --> 00:00:35.460
我们发现 每次一这么做

00:00:35.460 --> 00:00:37.110
我们的网络收敛速度

00:00:37.110 --> 00:00:39.360
就会快得多 相比之下

00:00:39.360 --> 00:00:41.430
我们的第一个网络难以收敛

00:00:41.430 --> 00:00:43.350
几乎无法达到常见的 60% 准确率

00:00:43.350 --> 00:00:44.730
运行速度仅为

00:00:44.730 --> 00:00:46.440
每秒 100 条评论左右

00:00:46.440 --> 00:00:49.350
我们的最后一个神经网络

00:00:49.350 --> 00:00:51.090
能以 86% 的准确率进行分类

00:00:51.090 --> 00:00:54.239
当我们仔细调参 它的分类速度可达

00:00:54.239 --> 00:00:57.690
每秒 7,000 条评论

00:00:57.690 --> 00:00:59.309
你会发现 这些解决问题的工具和技巧

00:00:59.309 --> 00:01:00.629
都非常地通用

00:01:00.629 --> 00:01:02.309
当你遇到

00:01:02.309 --> 00:01:03.660
一个新的数据集时

00:01:03.660 --> 00:01:04.830
你需要提出一个新的预测理论

00:01:04.830 --> 00:01:07.110
然后 根据数据调整模型

00:01:07.110 --> 00:01:09.119
让你数据中的相关性

00:01:09.119 --> 00:01:11.010
在神经网络中最为明显

00:01:11.010 --> 00:01:12.360
以使它们能够

00:01:12.360 --> 00:01:15.090
快速准确地进行预测

00:01:15.090 --> 00:01:16.080
希望你喜欢此教程

00:01:16.080 --> 00:01:17.729
并且继续享受其他优达学城课程

00:01:17.729 --> 00:01:24.200
好 让我们返回课堂吧

