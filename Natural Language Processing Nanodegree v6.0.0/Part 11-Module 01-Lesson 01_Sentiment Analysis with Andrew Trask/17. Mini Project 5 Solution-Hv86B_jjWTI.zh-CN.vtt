WEBVTT
Kind: captions
Language: zh-CN

00:00:00.240 --> 00:00:02.960
好 在这部分 我们提高了网络的效率

00:00:02.960 --> 00:00:06.529
通过去掉 * 1 提高了效率 因为根本不需要乘

00:00:06.530 --> 00:00:07.950
它不会带来任何改变

00:00:07.950 --> 00:00:12.132
而且 我们也去掉了对所有对含 0 单词的

00:00:12.132 --> 00:00:13.779
处理步骤

00:00:13.779 --> 00:00:16.750
这大大提高了我们网络的训练速度

00:00:16.750 --> 00:00:20.039
和测试速度 运行速度

00:00:20.039 --> 00:00:22.549
我们一会儿就会看到

00:00:22.550 --> 00:00:24.429
那么 为了实现这部分修改

00:00:24.429 --> 00:00:26.530
请注意 这个类最前面的部分并没有变化 对吧？

00:00:26.530 --> 00:00:29.130
所以我们依然初始化网络 依然创建同样的权重矩阵

00:00:29.129 --> 00:00:31.679
创建相同的单词索引查找表

00:00:32.859 --> 00:00:36.000
这些方法我都写了 但这里不会使用它们

00:00:36.000 --> 00:00:39.000
来到训练方法部分了 这才是改变真正开始的地方

00:00:39.000 --> 00:00:42.975
我在训练方法中添加了一个预处理步骤

00:00:42.975 --> 00:00:44.734
就是下面这些：

00:00:44.734 --> 00:00:49.115
它取 training_reviews_raw 里的每条评论

00:00:49.115 --> 00:00:53.150
也就是原始文本 然后创建一组索引

00:00:53.149 --> 00:00:55.289
因此 它将所有单词转换成数字了 对吧？

00:00:55.289 --> 00:00:57.320
也就是它们对应的行

00:00:57.320 --> 00:01:00.893
就像上面这里的 4 和 9 一样

00:01:00.893 --> 00:01:04.859
我们就得到了这个索引列表 可以将它们加到这个向量中

00:01:04.859 --> 00:01:07.679
最终 这个网络会变得非常非常快 这很好

00:01:08.739 --> 00:01:12.409
所以 我们在这里所做的 就像是上面步骤的放大版

00:01:12.409 --> 00:01:17.759
对于每条评论 我们将单词转换成它们在

00:01:17.760 --> 00:01:20.150
权重矩阵中对应的行

00:01:20.150 --> 00:01:23.440
所以我们的输入对应于矩阵中的行

00:01:23.439 --> 00:01:25.689
而输出对应于列 对吧？

00:01:25.689 --> 00:01:29.539
这就是在主矩阵中对乘法的处理

00:01:29.540 --> 00:01:34.511
这使我们可以在这里完全跳过创建

00:01:34.510 --> 00:01:35.661
输入向量

00:01:35.661 --> 00:01:38.609
我们在正向传播中完全可以省略这一步

00:01:38.609 --> 00:01:41.310
而是直接跳到创建隐藏层

00:01:41.310 --> 00:01:46.189
我们所做的 就是遍历评论中的每个索引

00:01:46.188 --> 00:01:50.746
然后将 weights_0_1 这行加到 layer_1

00:01:50.746 --> 00:01:53.219
我们取 layer_1 我们已在这里清空了它

00:01:53.219 --> 00:01:56.546
然后 对于 weights_0_1 中的每个行 将它添加到 layer_1

00:01:56.546 --> 00:02:02.189
我们所做的就是 对于每个行 将它添加到这些层

00:02:02.189 --> 00:02:05.754
所以 添加 horrible 的行 它是这个 添加 terrible 的行

00:02:05.754 --> 00:02:07.789
这里这个 将它添加到这里

00:02:07.790 --> 00:02:09.631
我们完全跳过了这个 (excellent) 以及

00:02:09.631 --> 00:02:12.879
这里提到的其他 70,000 多个单词

00:02:12.879 --> 00:02:14.867
这节省了大量的时间

00:02:14.867 --> 00:02:17.068
我真的很期望看到它的速度提升到多少

00:02:18.229 --> 00:02:22.491
那么 这部分是完全一样的 layer_2_error 完全一样

00:02:22.491 --> 00:02:24.409
layer_2_delta 也是一样

00:02:24.409 --> 00:02:28.668
layer_1 error 和 1_delta 也完全一样 因为什么都没改变

00:02:28.668 --> 00:02:33.206
唯一不同的一点是 我们更新权值的方式

00:02:33.206 --> 00:02:38.201
它基本与我们填充它的方式相反

00:02:38.201 --> 00:02:40.788
那么我们遍历相同的索引 然后说

00:02:40.788 --> 00:02:43.635
我们只更新那些正向传播的值

00:02:43.635 --> 00:02:47.269
我们使用过的那些值 所有其他的值都不管

00:02:47.270 --> 00:02:50.016
当你看看反向传播如何发生的 

00:02:50.015 --> 00:02:53.304
或者如何发生的 这就显得更有道理了

00:02:53.305 --> 00:02:58.302
当你计算这个最终 weight_delta 你的权重调整数值

00:02:58.301 --> 00:03:03.239
你用输入值乘以这里的增量

00:03:03.240 --> 00:03:05.870
反向传播增量 隐藏层中的增量

00:03:05.870 --> 00:03:10.566
那么 更新这四个索引的方式 是用 1 乘以这里的增量

00:03:10.566 --> 00:03:14.140
然后从这些权值中减去乘积

00:03:14.140 --> 00:03:19.060
现在的问题是 如果这个是 0 那么减的永远都是 0

00:03:19.061 --> 00:03:23.099
所以我们也可以跳过它 非常好

00:03:23.099 --> 00:03:25.759
这就是我们更新权值的方式

00:03:25.759 --> 00:03:28.745
所有的评估逻辑都是一样的 测试逻辑也是一样的

00:03:28.746 --> 00:03:29.951
运行逻辑也一样

00:03:29.950 --> 00:03:30.650
现在我们来试试看

00:03:30.650 --> 00:03:36.093
我们从上面抓取 SentimentNetwork 将它放在这里

00:03:36.093 --> 00:03:40.689
然后抓取实际的训练 只是一个参考

00:03:40.689 --> 00:03:46.551
这个训练每秒处理约 100 条评论

00:03:46.551 --> 00:03:51.818
将它放在这里 然后抓取测试

00:03:51.818 --> 00:03:56.235
我觉得训练速度应该是……

00:03:56.235 --> 00:04:00.975
我们应该会看到 我找找看

00:04:00.975 --> 00:04:05.974
每秒 1000 个评论 这是之前的十倍 超过十倍了

00:04:05.974 --> 00:04:10.987
看看 接近 1300 个 仍然在以相同的转换速度训练

00:04:10.987 --> 00:04:15.683
看看 每秒 1300 个评论 速度提高了一个数量集多

00:04:15.683 --> 00:04:20.555
因为我们摆脱了所有问题 像 COC 测试 

00:04:20.555 --> 00:04:24.810
说到测试 你几乎没注意到它有什么变化

00:04:24.810 --> 00:04:25.689
非常棒

00:04:25.689 --> 00:04:28.812
而且我们的得分也不错

00:04:28.812 --> 00:04:30.144
我是说它应该完全一样 对吧？

00:04:30.144 --> 00:04:33.800
因为什么都没有改变

00:04:33.800 --> 00:04:35.310
太棒了 这下快多了

00:04:37.129 --> 00:04:38.165
非常棒

00:04:38.165 --> 00:04:40.231
如果我们想 我们可以训练多次迭代 对吧？

00:04:40.232 --> 00:04:42.181
比如我说乘以 2

00:04:46.353 --> 00:04:48.492
我们点击训练 开始后

00:04:48.492 --> 00:04:50.964
它会将所有的东西转换为索引

00:04:50.964 --> 00:04:52.943
然后开始训练

00:04:52.944 --> 00:04:54.816
这里好像有点不清楚

00:04:54.815 --> 00:04:56.873
但是如果你继续进行更多的迭代

00:04:56.874 --> 00:04:58.300
它将使用相同的索引

00:04:58.300 --> 00:04:59.460
它只需转换一次索引

00:04:59.459 --> 00:05:02.810
哇塞 每秒评论数接近 1500 这非常快了

00:05:02.810 --> 00:05:06.910
我们可以继续训练 训练准确度继续提高

00:05:06.910 --> 00:05:09.310
网络的速度越高

00:05:09.310 --> 00:05:12.490
在给定时间段内你就能做更多迭代 对吧？

00:05:12.490 --> 00:05:16.394
那么我们做到这一切的方法是清除掉那些

00:05:16.394 --> 00:05:20.370
神经网络所做的但不能提高预测或者学习效果的

00:05:20.370 --> 00:05:22.319
操作步骤

00:05:22.319 --> 00:05:26.189
这就是我们真正的策略

00:05:26.189 --> 00:05:29.920
那么 在下一部分 我们将回到数据上

00:05:29.920 --> 00:05:33.300
看看 我们能否改进模型？

00:05:33.300 --> 00:05:36.600
我们改进了问题的架构方式

00:05:36.600 --> 00:05:40.879
是否因为我们训练的方法得当

00:05:40.879 --> 00:05:43.269
改进了神经网络的正向和反向传播？

00:05:43.269 --> 00:05:47.719
由于我们的设置中 只将词汇表向前传递

00:05:47.720 --> 00:05:52.190
这去除了神经网络中的很多低效率的计算浪费

00:05:52.189 --> 00:05:52.889
现在 我们要返回去

00:05:52.889 --> 00:05:57.889
看我们是否可以再次重构这个问题 进一步减少噪音

00:05:57.889 --> 00:06:00.469
并且减少更多的权值传播

00:06:00.470 --> 00:06:04.160
以加快学习速度和实际的计算速度？

00:06:04.160 --> 00:06:07.250
所以我们将在项目六中再做一次迭代

00:06:07.250 --> 00:06:07.709
到时候见

