WEBVTT
Kind: captions
Language: en

00:00:00.790 --> 00:00:04.450
(speaker) So here I am
calculating the output.

00:00:04.450 --> 00:00:06.820
So like I said
before, we're only

00:00:06.820 --> 00:00:09.080
really concerned with
the final output,

00:00:09.080 --> 00:00:12.160
which is what we're going to
use to predict our sentiment.

00:00:12.160 --> 00:00:13.839
So we just need to
grab the last one

00:00:13.839 --> 00:00:16.839
and we can do that
using outputs.

00:00:16.839 --> 00:00:19.929
So this is saying, give us all
the rows, so all the batches.

00:00:19.929 --> 00:00:23.774
And this is saying,
give us the last column.

00:00:23.774 --> 00:00:25.690
Remember that we're
passing a bunch of reviews

00:00:25.690 --> 00:00:28.450
in at the same time
because that's our batch,

00:00:28.449 --> 00:00:34.079
and then the last column is just
the last output from our LSTM

00:00:34.079 --> 00:00:35.390
cells.

00:00:35.390 --> 00:00:37.890
So this last output
is this arrow here,

00:00:37.890 --> 00:00:40.039
is the last output
from the LSTM cells,

00:00:40.039 --> 00:00:42.939
and we're ignoring all
these other outputs.

00:00:42.939 --> 00:00:48.699
So then these
outputs from the LSTM

00:00:48.700 --> 00:00:52.179
are just going to a fully
connected layer that

00:00:52.179 --> 00:00:53.920
only has one unit
because we're just

00:00:53.920 --> 00:00:57.219
doing this one like
sigmoid predictor unit.

00:00:57.219 --> 00:01:01.210
So the activation function
is here, tf.sigmoid,

00:01:01.210 --> 00:01:03.200
and this gives us
our prediction.

00:01:03.200 --> 00:01:05.730
So remember that sigmoid
is always between 0 and 1,

00:01:05.730 --> 00:01:09.760
so you can treat it as a
probability that is true,

00:01:09.760 --> 00:01:12.160
it's a probability
that is positive.

00:01:12.159 --> 00:01:14.679
Then here we're just using
our labels and our predictions

00:01:14.680 --> 00:01:17.680
to calculate the cost with
the mean squared error.

00:01:17.680 --> 00:01:20.030
And finally, we have
our AdamOptimizer

00:01:20.030 --> 00:01:23.329
that is going to minimize our
cost and train the weights.

00:01:23.329 --> 00:01:26.890
And here I added this
little bit to use

00:01:26.890 --> 00:01:29.109
as a validation accuracy.

00:01:29.109 --> 00:01:31.719
So I'm just rounding
our predictions,

00:01:31.719 --> 00:01:35.879
because remember predictions
are somewhere between 0 and 1.

00:01:35.879 --> 00:01:38.949
But we want them to be 0
and 1 so that we can say,

00:01:38.950 --> 00:01:41.659
is it equal to our labels?

00:01:41.659 --> 00:01:43.390
So here I'm just
rounding predictions,

00:01:43.390 --> 00:01:47.239
so this makes it either 0 or 1,
depending on what the value is.

00:01:47.239 --> 00:01:50.259
And then I'm going to
change the data type,

00:01:50.260 --> 00:01:53.340
I'm going to cast it to an int
because our labels are ints.

00:01:53.340 --> 00:01:56.439
So we want these to have the
same data types so that we

00:01:56.439 --> 00:02:01.780
can do this check of equality.

00:02:01.780 --> 00:02:04.853
Remember that we're passing
in a bunch of batches.

00:02:04.853 --> 00:02:07.269
So we have a batch and we're
passing in a bunch of reviews

00:02:07.269 --> 00:02:08.508
with each batch.

00:02:08.508 --> 00:02:10.870
So now we actually
want to find the mean

00:02:10.870 --> 00:02:13.509
for all these accuracies.

00:02:13.509 --> 00:02:16.479
To do that, we're going
to use tf.reduce_mean,

00:02:16.479 --> 00:02:19.780
so this just finds the mean
of all the predictions,

00:02:19.780 --> 00:02:21.860
and it's going to
give us our accuracy.

00:02:21.860 --> 00:02:24.970
So here, correct
prediction is actually

00:02:24.969 --> 00:02:28.870
a boolean, that's what the
data type comes out of equal.

00:02:28.870 --> 00:02:30.730
So we actually have to
cast this to a float

00:02:30.729 --> 00:02:32.439
to get it to work
in reduce_mean.

00:02:32.439 --> 00:02:35.310
So that's what's going on here.

00:02:35.310 --> 00:02:39.210
Then here is just a function
to get batches for us.

00:02:39.210 --> 00:02:41.760
So you can read this
text and read through it,

00:02:41.759 --> 00:02:44.099
but this is pretty typical.

00:02:44.099 --> 00:02:45.960
So basically I just
have two arrays

00:02:45.960 --> 00:02:50.250
x and y and then here
I'm just making sure

00:02:50.250 --> 00:02:52.530
that every batch is a full
batch, so I'm kind of just

00:02:52.530 --> 00:02:54.289
getting rid of extra data.

00:02:54.289 --> 00:02:57.060
And then I'm just looping
through each of these arrays

00:02:57.060 --> 00:03:01.469
and in this case
yielding batches.

00:03:01.469 --> 00:03:04.349
And finally, this code
is the training code.

00:03:04.349 --> 00:03:08.219
So this is a lot of code
and it's pretty standard.

00:03:08.219 --> 00:03:10.229
This is really similar
to training code

00:03:10.229 --> 00:03:12.509
that I write in every
single of these notebooks.

00:03:12.509 --> 00:03:15.840
So if you want to kind of like
an extra challenge to you,

00:03:15.840 --> 00:03:18.200
just go ahead and
delete this entire cell

00:03:18.199 --> 00:03:22.560
and then try to
implement it yourself.

00:03:22.560 --> 00:03:25.620
One way, probably the best
way to learn this stuff,

00:03:25.620 --> 00:03:28.050
is to actually type everything
yourself, because that's

00:03:28.050 --> 00:03:30.180
sort of the deal with
tutorials, is that you just

00:03:30.180 --> 00:03:32.040
read these tutorials and
you think you learned it

00:03:32.039 --> 00:03:33.789
but then you try to
do it and it turns out

00:03:33.789 --> 00:03:36.609
you didn't learn it because
you didn't type it in yourself.

00:03:36.610 --> 00:03:39.660
So it would probably
be a good idea for you

00:03:39.659 --> 00:03:43.199
to just delete all this training
code and try to implement it

00:03:43.199 --> 00:03:43.989
yourself.

00:03:43.990 --> 00:03:45.990
And of course, you can
copy this to another file

00:03:45.990 --> 00:03:49.409
so you can look at that
and see how you're doing.

00:03:49.409 --> 00:03:52.049
And finally, we have
testing code down here.

00:03:52.050 --> 00:03:56.160
So I will let you build
all this, do the exercises,

00:03:56.159 --> 00:03:58.359
and run this code.

00:03:58.360 --> 00:04:00.660
And if you have
problems with this,

00:04:00.659 --> 00:04:03.030
I'm going to have a solution
video also and a solution

00:04:03.030 --> 00:04:05.180
notebook so you can
see how I did all this.

00:04:05.180 --> 00:04:07.210
OK, cheers!

