WEBVTT
Kind: captions
Language: pt-BR

00:00:00.300 --> 00:00:02.067
Olá, pessoal!
Bem-vindos de volta.

00:00:02.533 --> 00:00:06.300
Agora vamos começar
de fato a construir a rede.

00:00:06.967 --> 00:00:11.467
Aqui podemos ver a estrutura geral
da rede que vamos construir.

00:00:11.500 --> 00:00:13.767
Temos os nossos inputs
e, como eu já disse,

00:00:13.800 --> 00:00:16.900
nós não vamos usar
codificação one-hot,

00:00:16.933 --> 00:00:18.733
vamos passar
números inteiros.

00:00:18.767 --> 00:00:21.033
Vamos passá-los
para esta camada oculta,

00:00:21.067 --> 00:00:22.500
que é a nossa camada
de embedding.

00:00:22.533 --> 00:00:24.200
Isso são só
neurônios lineares,

00:00:24.233 --> 00:00:28.767
então não vamos ativá-los.
Eles são apenas lineares.

00:00:28.800 --> 00:00:32.667
E isto vai para uma camada
de saída softmax.

00:00:33.867 --> 00:00:37.800
Lembre-se de que estamos
passando textos lineares

00:00:37.833 --> 00:00:39.933
e, depois, palavras alvo.

00:00:39.967 --> 00:00:43.633
Assim, vamos tentar prever
nossas palavras alvo

00:00:43.667 --> 00:00:45.533
usando esta camada softmax.

00:00:47.267 --> 00:00:49.833
Depois que treinarmos tudo,

00:00:49.867 --> 00:00:53.433
o que vai acontecer
é que a nossa camada oculta

00:00:53.467 --> 00:00:57.300
vai formar essas representações
vetoriais das palavras

00:00:57.333 --> 00:00:59.300
que contêm significado
semântico.

00:00:59.333 --> 00:01:00.933
É nisso
que estamos interessados.

00:01:00.967 --> 00:01:04.600
São só essas representações
que nos importam,

00:01:04.633 --> 00:01:07.767
já que estamos transformando
estas palavras em vetores.

00:01:07.800 --> 00:01:09.800
Isso significa que,
depois de treinarmos,

00:01:09.833 --> 00:01:12.100
podemos descartar
esta camada softmax,

00:01:12.133 --> 00:01:14.167
porque ela
não terá mais importância.

00:01:14.200 --> 00:01:18.100
Ela só está aí
para treinar os pesos

00:01:18.133 --> 00:01:19.800
entre os inputs
e a camada oculta.

00:01:20.733 --> 00:01:24.833
O primeiro passo
será construir os inputs.

00:01:25.833 --> 00:01:31.600
Aqui, vamos criar os inputs usando
espaços reservados do TensorFlow.

00:01:31.633 --> 00:01:33.967
Vamos passar
números inteiros,

00:01:34.000 --> 00:01:38.867
então precisamos configurar
o tipo dos dados para "tf.int32".

00:01:39.733 --> 00:01:43.433
Os lotes que vamos passar
terão tamanhos aleatórios,

00:01:43.467 --> 00:01:48.433
então vamos ter que deixar
o tamanho dos lotes arbitrário,

00:01:48.467 --> 00:01:50.633
podendo configurá-lo
para "none"

00:01:50.667 --> 00:01:53.567
que o TensorFlow vai se virar
quando passarmos os lotes.

00:01:54.400 --> 00:01:58.033
Para fazer as coisas funcionarem
mais à frente em partes do código,

00:01:58.067 --> 00:02:00.567
os rótulos, alvos

00:02:00.600 --> 00:02:03.267
e este espaço reservado precisarão
ter uma segunda dimensão,

00:02:03.300 --> 00:02:05.533
que devemos configurar
para "none" ou "1".

00:02:06.167 --> 00:02:09.733
Estes são os nós input.

00:02:09.767 --> 00:02:13.433
Aqui embaixo, vemos a nossa
camada de embedding.

00:02:14.667 --> 00:02:17.567
Aqui, você vai criar
a sua camada de embedding,

00:02:17.600 --> 00:02:21.800
e o primeiro passo
é criar a matriz de embedding.

00:02:21.833 --> 00:02:26.967
Ela terá o tamanho do número
de palavras do seu vocabulário

00:02:27.000 --> 00:02:30.000
vezes as suas dimensões
de embedding desejadas.

00:02:31.033 --> 00:02:33.000
Por exemplo,
se você tiver 10 mil palavras

00:02:33.033 --> 00:02:36.367
e 300 unidades ocultas,
que são sua dimensão de embedding,

00:02:36.400 --> 00:02:39.333
a matriz será
de 10 mil x 300.

00:02:39.800 --> 00:02:45.000
Aqui, você vai configurar
o número de recursos de embedding

00:02:45.033 --> 00:02:46.467
e de dimensões de embedding

00:02:46.500 --> 00:02:50.500
e vai criar a matriz
de embedding de peso aqui.

00:02:50.533 --> 00:02:52.967
Lembre-se de que fazemos isso
com o "tf.variable".

00:02:53.000 --> 00:02:55.300
Agora, para fazer a pesquisa
de fato,

00:02:55.333 --> 00:02:58.300
usamos
"tf.nn.embedding_lookup".

00:02:58.333 --> 00:03:01.667
Você pode ler
a documentação aqui,

00:03:01.700 --> 00:03:05.167
mas, basicamente,
você pode passar

00:03:05.200 --> 00:03:10.667
a matriz de peso
e, depois, um número inteiro

00:03:10.700 --> 00:03:12.100
e a pesquisa é realizada.

00:03:12.133 --> 00:03:14.667
Ou você pode passar
um tensor de números inteiros

00:03:14.700 --> 00:03:17.167
e a pesquisa será realizada
em todos os tensores.

00:03:17.200 --> 00:03:20.567
Assim, você obterá os valores
da sua camada oculta.

00:03:21.233 --> 00:03:23.433
Então, eu vou deixar você
trabalhar nisso.

00:03:23.467 --> 00:03:29.367
Aqui, você vai criar os inputs
e a camada de embedding.

00:03:30.167 --> 00:03:32.267
Se precisar de ajuda,
veja minhas soluções

00:03:32.300 --> 00:03:35.200
e temos um vídeo
com a minha solução a seguir.

