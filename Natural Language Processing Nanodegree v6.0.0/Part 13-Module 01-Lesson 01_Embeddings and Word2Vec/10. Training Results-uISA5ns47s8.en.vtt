WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.674
Okay, so the rest of this is the validation code so we can,

00:00:04.674 --> 00:00:09.615
kind of, keep track of the performance of our word2vec network as it's training.

00:00:09.615 --> 00:00:12.532
And then here is some training code.

00:00:12.532 --> 00:00:13.750
This is, you know,

00:00:13.750 --> 00:00:16.803
fairly, fairly typical way of doing it.

00:00:16.803 --> 00:00:19.884
So you just create your batches and then create

00:00:19.885 --> 00:00:24.828
a feed dictionary and pass it into your network and run the optimizer.

00:00:24.827 --> 00:00:27.425
So then here as it's training,

00:00:27.425 --> 00:00:28.820
we'll be printing out

00:00:28.820 --> 00:00:32.755
the training loss so you should be seeing this drop as it's going on.

00:00:32.755 --> 00:00:37.145
And then we're also printing out some words for validation.

00:00:37.145 --> 00:00:42.634
So what we did here is just kind of randomly sample some target words,

00:00:42.634 --> 00:00:47.090
some kind of like example words and then we're looking at, you know,

00:00:47.090 --> 00:00:51.820
words in our dataset where the vector representations are close.

00:00:51.820 --> 00:00:56.195
Right? So this, we can see like, oh, is our,

00:00:56.195 --> 00:00:58.634
is our network actually learning,

00:00:58.634 --> 00:01:01.673
you know, semantic relationships between these words?

00:01:01.673 --> 00:01:04.549
So as it is learning you should start

00:01:04.549 --> 00:01:07.939
seeing like words that are related to called being close to called.

00:01:07.938 --> 00:01:09.809
So this is showing like, okay,

00:01:09.810 --> 00:01:14.069
nearest to the word for is Hoffman, rogue, Montinari.

00:01:14.069 --> 00:01:16.730
I mean these words obviously do not have

00:01:16.730 --> 00:01:19.790
anything to do with any of this stuff or like consists,

00:01:19.790 --> 00:01:23.120
you know, scale, like it doesn't really have anything to do with this.

00:01:23.120 --> 00:01:27.665
But at the end like when we, when we have this all trained up,

00:01:27.665 --> 00:01:29.849
we can see, you know, like the word scale,

00:01:29.849 --> 00:01:33.109
the, the word diatonic is close to scale and this is, you know,

00:01:33.108 --> 00:01:38.000
a musical phrase or we have units and unit, ice rink,

00:01:38.000 --> 00:01:40.129
USSR, hockey, Sweden, you know,

00:01:40.129 --> 00:01:42.019
like a lot of this has to do with,

00:01:42.019 --> 00:01:44.434
you know, hockey, like ice rink, hockey.

00:01:44.433 --> 00:01:50.093
So we can, we can use this to actually get a sense of how our,

00:01:50.093 --> 00:01:55.953
our network is learning and how these representations are actually,

00:01:55.953 --> 00:01:58.983
you know, getting closer to each other in a way that we want.

00:01:58.983 --> 00:02:04.188
Okay, so then finally here I am using T-SNE to, kind of,

00:02:04.188 --> 00:02:08.763
group our vectors together so we can get a visualization

00:02:08.764 --> 00:02:13.520
of like how these representations actually exist in this,

00:02:13.520 --> 00:02:16.280
sort of, you know, high dimensional space.

00:02:16.280 --> 00:02:20.449
So what we expect to see is that words that have similar meanings are

00:02:20.449 --> 00:02:25.134
going to be closer together and that's basically exactly what we see.

00:02:25.133 --> 00:02:27.438
So here we have like Central,

00:02:27.438 --> 00:02:30.432
East, Western, West, South, North America.

00:02:30.432 --> 00:02:34.698
So, you know, these all like exist in the same, same context,

00:02:34.699 --> 00:02:40.810
and so then we see them grouped together with our, our semantic representations.

00:02:40.810 --> 00:02:43.695
Then over here you have school, university, college.

00:02:43.695 --> 00:02:47.935
Down here we have like open source, free, software.

00:02:47.935 --> 00:02:49.218
So you know, like all these things,

00:02:49.218 --> 00:02:52.489
so it's a pretty good indication that our network has actually

00:02:52.490 --> 00:02:57.490
learned like some information about like the meaning of these words.

00:02:57.490 --> 00:03:01.330
Okay, I hope you enjoyed building this.

00:03:01.330 --> 00:03:04.610
This is a really cool like architecture,

00:03:04.610 --> 00:03:08.344
a really cool model that has proven to

00:03:08.343 --> 00:03:13.000
be really useful in representing language. Okay, cheers.
最新课程跟课件还有一对一辅导请加wx：udacity6
