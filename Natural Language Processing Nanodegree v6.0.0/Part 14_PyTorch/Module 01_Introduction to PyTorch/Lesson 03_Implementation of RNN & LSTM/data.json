{
  "data": {
    "lesson": {
      "id": 730868,
      "key": "bdd94592-32b2-400a-a081-dadda18974df",
      "title": "Implementation of RNN & LSTM",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Learn how to represent memory in code. Then define and train RNNs in PyTorch and apply them to tasks that involve sequential data.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": false,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/bdd94592-32b2-400a-a081-dadda18974df/730868/1540244861597/Implementation+of+RNN+%26+LSTM+%5Bnew%5D+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/bdd94592-32b2-400a-a081-dadda18974df/730868/1540244857850/Implementation+of+RNN+%26+LSTM+%5Bnew%5D+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 730869,
          "key": "054c2de2-09b8-4d0c-8b35-4d6ad8a4fafa",
          "title": "Implementing RNNs",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "054c2de2-09b8-4d0c-8b35-4d6ad8a4fafa",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751843,
              "key": "685ccd5e-4273-4b13-860d-8175f19fdcf9",
              "title": "M4L31 HSA Implementing RNNs V2 RENDERv1 V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "BHoiwB61ays",
                "china_cdn_id": "BHoiwB61ays.mp4"
              }
            }
          ]
        },
        {
          "id": 730872,
          "key": "75b86f72-a241-4df3-8eb3-d688835f0b93",
          "title": "Time-Series Prediction",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "75b86f72-a241-4df3-8eb3-d688835f0b93",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751845,
              "key": "9ade4f19-5a96-4d2b-b412-c41460a56028",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Code Walkthrough & Repository \n\nThe below video is a walkthrough of code that you can find in our public Github repository, if you navigate to `recurrent-neural-networks > time-series` and [the Simple_RNN.ipynb notebook](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/time-series/Simple_RNN.ipynb). Feel free to go through this code on your own, locally. \n\nThis example is meant to give you an idea of how PyTorch represents RNNs and how you might represent memory in code. Later, you'll be given more complex exercise and solution notebooks, in-classroom.",
              "instructor_notes": ""
            },
            {
              "id": 751844,
              "key": "805afa7c-4fe8-40a7-96bb-c8fa2156cd4a",
              "title": "02 Time Series Prediction V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "xV5jHLFfJbQ",
                "china_cdn_id": "xV5jHLFfJbQ.mp4"
              }
            }
          ]
        },
        {
          "id": 730873,
          "key": "d69b005f-8855-4990-89db-9ab3af3ec7dc",
          "title": "Training & Memory",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "d69b005f-8855-4990-89db-9ab3af3ec7dc",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751852,
              "key": "e78bb123-cd4a-499f-88e3-724d8b25c376",
              "title": "03 Training Memory V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "sx7T_KP5v9I",
                "china_cdn_id": "sx7T_KP5v9I.mp4"
              }
            },
            {
              "id": 751854,
              "key": "7af4de37-1b2a-4f7b-8bce-20712f5d1dd1",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Recurrent Layers\n\nHere is the documentation for the main types of [recurrent layers in PyTorch](https://pytorch.org/docs/stable/nn.html#recurrent-layers). Take a look and read about the three main types: RNN, LSTM, and GRU.\n\n",
              "instructor_notes": ""
            },
            {
              "id": 751855,
              "key": "a9c608f4-5e5e-4fce-91a4-4eebfa75f5e5",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Hidden State Dimensions",
              "instructor_notes": ""
            },
            {
              "id": 751862,
              "key": "fdbd5f69-acce-4d08-928e-e9d9f8949fc5",
              "title": "",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "fdbd5f69-acce-4d08-928e-e9d9f8949fc5",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Say you've defined a GRU layer with `input_size = 100`, `hidden_size = 20`, and `num_layers=1`.\nWhat will the dimensions of the hidden state be if you're passing in data, batch first, in batches of 3 sequences at a time?",
                "answers": [
                  {
                    "id": "a1539659912593",
                    "text": "`(1, 1, 20)`",
                    "is_correct": false
                  },
                  {
                    "id": "a1539660094445",
                    "text": "`(1, 1, 100)`",
                    "is_correct": false
                  },
                  {
                    "id": "a1539660099136",
                    "text": "`(1, 3, 20)`",
                    "is_correct": true
                  },
                  {
                    "id": "a1539660107884",
                    "text": "`(1, 3, 100)`",
                    "is_correct": false
                  },
                  {
                    "id": "a1539660241639",
                    "text": "`(3, 1, 20)`",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 305304,
          "key": "6538eb14-1ec2-4a25-bc73-5942a48b1141",
          "title": "Character-wise RNNs",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "6538eb14-1ec2-4a25-bc73-5942a48b1141",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 306074,
              "key": "a1b53a77-896f-46d1-9827-2127679400fc",
              "title": "Character-Wise RNN",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "dXl3eWCGLdU",
                "china_cdn_id": "dXl3eWCGLdU.mp4"
              }
            }
          ]
        },
        {
          "id": 305305,
          "key": "5a65c5b3-5cfc-4753-bcde-25a490978e6c",
          "title": "Sequence Batching",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "5a65c5b3-5cfc-4753-bcde-25a490978e6c",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 306077,
              "key": "3eb4b04b-ea18-44b9-82fe-ad8d094bca10",
              "title": "Sequence-Batching",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "Z4OiyU0Cldg",
                "china_cdn_id": "Z4OiyU0Cldg.mp4"
              }
            }
          ]
        },
        {
          "id": 730871,
          "key": "a6e5d808-b0c3-42b0-b16c-72ca3604984d",
          "title": "Pre-Notebook: Character-Level RNN",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "a6e5d808-b0c3-42b0-b16c-72ca3604984d",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751835,
              "key": "7811c4c8-3e48-462e-8fd5-04d1b8dfd538",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Notebook: Character-Level RNN\n\nNow you have all the information you need to implement an RNN of our own. The next few videos will be all about character-level text prediction with an LSTM!\n\n**It's suggested that you open the notebook in a new, working tab and continue working on it as you go through the instructional videos in this tab.** This way you can toggle between learning new skills and coding/applying new skills.\n\nTo open this notebook, you have two options:\n>- Go to the next page in the classroom (recommended).\n- Clone the repo from [Github](https://github.com/udacity/deep-learning-v2-pytorch) and open the notebook **Character_Level_RNN_Exercise.ipynb** in the **recurrent-neural-networks > char-rnn** folder.  You can either download the repository with `git clone https://github.com/udacity/deep-learning-v2-pytorch.git`, or download it as an archive file from [this link](https://github.com/udacity/deep-learning-v2-pytorch/archive/master.zip).\n\n# Instructions\n\n* Load in text data\n* Pre-process that data, encoding characters as integers and creating one-hot input vectors\n* Define an RNN that predicts the *next* character when given an input sequence\n* Train the RNN and use it to generate *new* text\n\nThis is a self-assessed lab. If you need any help or want to check your answers, feel free to check out the solutions notebook in the same folder, or by clicking [here](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/Character_Level_RNN_Solution.ipynb).",
              "instructor_notes": ""
            },
            {
              "id": 751836,
              "key": "39651a21-94f2-4958-ae65-1d0079c1b188",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### GPU Workspaces\n\nThe next workspace is **GPU-enabled**, which means you can select to train on a GPU instance. The recommendation is this:\n* Load in data, test functions and models (checking parameters and doing a short training loop) while in CPU (non-enabled) mode\n* When you're ready to extensively train and test your model, **enable** GPU to quickly train the model!\n\nAll models and data they see as input will have to be moved to the GPU device, so take note of the relevant movement code in the model creation and training process.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 730874,
          "key": "736e0829-5ccc-4a67-93f0-d41454410670",
          "title": "Notebook: Character-Level RNN",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "736e0829-5ccc-4a67-93f0-d41454410670",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751837,
              "key": "0db37747-e812-49e3-8576-eaf0ee16f49a",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "view0qauv3pxlus",
              "pool_id": "jupytergpu",
              "view_id": "jupyter-ya5k28up3a",
              "gpu_capable": true,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": null,
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/Character_Level_RNN_Exercise.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 751838,
          "key": "04794f8a-7728-4c0a-a808-aa7972bc7738",
          "title": "Implementing a Char-RNN",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "04794f8a-7728-4c0a-a808-aa7972bc7738",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751868,
              "key": "2faf34a9-34f1-4887-ae85-e9224e4391a7",
              "title": "04 Implementing CharRNN V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "MMtgZXzFB10",
                "china_cdn_id": "MMtgZXzFB10.mp4"
              }
            },
            {
              "id": 751885,
              "key": "309d905c-013f-4f27-ad51-905d8db9d373",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "*Typo: Above you may see the title, `Chararacter_Level_RNN_Exercise`. This is a mistake on my part and the in-classroom notebooks have been updated with the correct spelling.* \n\nKnow that the code is correct even if the title has a typo :) ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 751839,
          "key": "dc32e24e-62ef-4339-b455-fd3d905b5211",
          "title": "Batching Data, Solution",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "dc32e24e-62ef-4339-b455-fd3d905b5211",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751869,
              "key": "993bfdd1-b9d6-47a4-abe2-5345ad2e3024",
              "title": "05 Batching Data V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "9Eg0wf3eW-k",
                "china_cdn_id": "9Eg0wf3eW-k.mp4"
              }
            }
          ]
        },
        {
          "id": 751840,
          "key": "a08bb8eb-fb71-4012-8a17-b78c841b68fb",
          "title": "Defining the Model",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "a08bb8eb-fb71-4012-8a17-b78c841b68fb",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751870,
              "key": "9823eb22-5e36-4a56-9192-3db886b87a37",
              "title": "06 Defining Model V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "_LWzyqq4hCY",
                "china_cdn_id": "_LWzyqq4hCY.mp4"
              }
            },
            {
              "id": 766542,
              "key": "33a2fb6b-8ba5-46ef-b402-6dfab765b0b4",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "#### Contiguous variables\n\nIf you are stacking up multiple LSTM outputs, it may be necessary to use `.contiguous()` to reshape the output. The notebook and Github repo code has been updated to include this use case in the `forward` function of the model:\n```\n# stack up LSTM outputs\nout = out.contiguous().view(-1, self.n_hidden)\n```",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 751841,
          "key": "284fab25-93cb-4192-840e-371f0c75cc07",
          "title": "Char-RNN, Solution",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "284fab25-93cb-4192-840e-371f0c75cc07",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751871,
              "key": "e4d229ba-07c0-436f-9bb9-7449557ba7b6",
              "title": "07 CharRNN Solution V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "ed33qePHrJM",
                "china_cdn_id": "ed33qePHrJM.mp4"
              }
            },
            {
              "id": 751874,
              "key": "c798b2ac-6d16-454c-bb51-411bea065111",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Representing Memory\n\nYou’ve learned that RNN’s work well for sequences of data because they have a kind of memory. This memory is represented by something called the **hidden state**.\n\nIn the character-level LSTM example, each LSTM cell, in addition to accepting a character as input and generating an output character, also has some hidden state, and each cell will pass along its hidden state to the next cell. \n\nThis connection creates a kind of memory by which a series of cells can remember which characters they’ve just seen and use that information to inform the next prediction!\n\nFor example, if a cell has just generated the character `a` it likely will *not* generate another `a`, right after that!\n",
              "instructor_notes": ""
            },
            {
              "id": 766544,
              "key": "55f2b211-c380-43e1-9d4d-72314754289b",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "#### `net.eval()`\n\nThere is an omission in the above code: including `net.eval()` !\n\n`net.eval(`) will set all the layers in your model to evaluation mode. This affects layers like dropout layers that turn \"off\" nodes during training with some probability, but should allow every node to be \"on\" for evaluation. So, you should set your model to evaluation mode **before testing or validating your model**, and before, for example, sampling and making predictions about the likely next character in a given sequence. I'll set net.train()` (training mode) only during the training loop. \n\nThis is reflected in the previous notebook code and in our [Github repository](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn).",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 751842,
          "key": "ecaff24e-7314-43b1-a11d-49762fa5c5ff",
          "title": "Making Predictions",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "ecaff24e-7314-43b1-a11d-49762fa5c5ff",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751875,
              "key": "146c5fbc-1939-4c73-87a7-30b1fb5debe8",
              "title": "08 Making Predictions V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "BhrpV3kwATo",
                "china_cdn_id": "BhrpV3kwATo.mp4"
              }
            },
            {
              "id": 751882,
              "key": "d2625806-47ba-45b6-99d1-8d90af18752f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Examples of RNNs\n\nTake a look at one of my favorite examples of RNNs making predictions based on some user-generated input dat: the [sketch-rnn by Magenta](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html). This RNN takes as input a starting sketch, drawn by you, and then tries to complete your sketch using a particular model. For example, it can learn to complete a sketch of a pineapple or the mona lisa!",
              "instructor_notes": ""
            },
            {
              "id": 751884,
              "key": "fddd9725-74f8-438f-ba31-7b767de4227e",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/October/5bc55cf8_screen-shot-2018-10-15-at-8.35.15-pm/screen-shot-2018-10-15-at-8.35.15-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/fddd9725-74f8-438f-ba31-7b767de4227e",
              "caption": "Example sketch-rnn output of the mona lisa.",
              "alt": "",
              "width": 2543,
              "height": 1016,
              "instructor_notes": null
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}