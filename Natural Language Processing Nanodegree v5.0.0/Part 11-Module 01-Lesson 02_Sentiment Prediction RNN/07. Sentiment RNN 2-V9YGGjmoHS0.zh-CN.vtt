WEBVTT
Kind: captions
Language: zh-CN

00:00:00.660 --> 00:00:01.830
欢迎回来

00:00:01.830 --> 00:00:04.200
现在我将针对之前布置的练习

00:00:04.200 --> 00:00:07.620
讲解我的解决方案

00:00:07.620 --> 00:00:10.560
猜测你之所以观看该视频

00:00:10.560 --> 00:00:13.800
可能是因为你无法实现代码

00:00:13.800 --> 00:00:16.170
或者就是想看看我是怎么实现的

00:00:16.170 --> 00:00:18.330
也许你的方法与我的不一样

00:00:18.329 --> 00:00:20.049
这也没关系

00:00:20.050 --> 00:00:21.900
编程嘛

00:00:21.899 --> 00:00:24.479
肯定有数千种不同的方式

00:00:24.480 --> 00:00:26.800
这只是我的方式

00:00:26.800 --> 00:00:31.839
首先 我用整数表示单词

00:00:31.839 --> 00:00:33.399
我实际上

00:00:33.399 --> 00:00:37.993
要按单词出现频率来赋值

00:00:37.993 --> 00:00:40.159
频率最高的单词将为 1

00:00:40.159 --> 00:00:42.729
下一个是 2 以此类推

00:00:42.729 --> 00:00:45.789
在此练习中这么做并没什么显著的优势

00:00:45.789 --> 00:00:49.780
但是当我使用 Word2Vec 模型时 却有很大的帮助

00:00:49.780 --> 00:00:52.579
所以我喜欢这么设置

00:00:52.579 --> 00:00:55.449
如果你没这么做 也没关系

00:00:55.450 --> 00:00:57.970
我使用了Counter 类来计算

00:00:57.969 --> 00:01:00.009
所有单词的频率

00:01:00.009 --> 00:01:04.840
然后对其进行排序

00:01:04.840 --> 00:01:07.420
以便根据单词频率获得 vocab

00:01:07.420 --> 00:01:11.409
这里我使用字典推导式

00:01:11.409 --> 00:01:14.619
构建字典 即词汇到整数字典

00:01:14.620 --> 00:01:17.650
对词汇进行枚举

00:01:17.650 --> 00:01:22.120
并从 1 开始 获取索引 整数

00:01:22.120 --> 00:01:25.570
和单词 将单词设为键

00:01:25.569 --> 00:01:27.459
并将整数设为值

00:01:30.790 --> 00:01:33.370
正如我之前提到的 我们想从 1 开始

00:01:33.370 --> 00:01:38.420
而不是 0 因为稍后将用 0 填充向量

00:01:38.420 --> 00:01:43.480
如果你将某些单词计数为 0

00:01:43.480 --> 00:01:46.150
例如“the”用 0 表示 那么稍后网络看到 0 的话

00:01:46.150 --> 00:01:48.407
会以为所有的都是单词“it”或其他单词

00:01:48.406 --> 00:01:50.739
或“the” 因为我认为“the”

00:01:50.739 --> 00:01:52.869
通常是出现频率最高的单词

00:01:52.870 --> 00:01:57.880
我在这里将影评从单词转换为整数

00:01:57.879 --> 00:02:00.009
同样使用了推导式

00:02:00.010 --> 00:02:02.140
这次是列表推导式

00:02:02.140 --> 00:02:06.670
从影评中获取每条影评

00:02:06.670 --> 00:02:09.939
并拆分为单词 然后对于每个单词

00:02:09.939 --> 00:02:11.770
我都将其转换为整数

00:02:11.770 --> 00:02:13.450
然后使用列表推导式

00:02:13.449 --> 00:02:16.489
使用这些整数构建新的列表

00:02:16.490 --> 00:02:21.050
并将其附加到这个新列表“reviews_ints”后面

00:02:21.050 --> 00:02:24.740
这样 我可以构建这个由列表组成的列表

00:02:24.740 --> 00:02:26.960
每个内部列表都是一个影评

00:02:26.960 --> 00:02:30.629
其中单词已转换为整数

00:02:34.270 --> 00:02:37.280
我在这里对标签进行编码

00:02:37.280 --> 00:02:40.400
也就是将标签

00:02:40.400 --> 00:02:43.740
从 positive 和 negative 分别改成

00:02:43.740 --> 00:02:45.300
1 和 0

00:02:45.300 --> 00:02:48.080
对我来说 很直白

00:02:48.080 --> 00:02:51.260
我只是使用了另一个列表推导式

00:02:51.259 --> 00:02:52.789
我使用了很多列表推导式

00:02:52.789 --> 00:02:54.409
因为我真的很喜欢列表推导式

00:02:54.409 --> 00:02:58.181
从 labels 中获取每个标签

00:02:58.181 --> 00:02:59.389
然后进行这项测试

00:02:59.389 --> 00:03:03.949
如果该标签是 positive 则等于 1

00:03:03.949 --> 00:03:04.701
否则等于 0

00:03:04.701 --> 00:03:07.159
这样可以循环访问整个数组

00:03:07.159 --> 00:03:09.139
构建新的列表 然后将其改为

00:03:09.139 --> 00:03:11.269
标签数组

00:03:13.900 --> 00:03:18.760
我通常喜欢将我的数据保持为 NumPy 数组

00:03:18.759 --> 00:03:21.489
而不是列表 因为这样处理起来更轻松

00:03:21.490 --> 00:03:23.080
任何时候

00:03:23.080 --> 00:03:25.390
以任何方式处理数据

00:03:25.389 --> 00:03:28.449
使用 NumPy 数组都比

00:03:28.449 --> 00:03:31.289
普通的 Python 列表要方便

00:03:31.289 --> 00:03:36.219
这里我滤除了长度为 0 的影评

00:03:36.219 --> 00:03:38.830
我比较懒

00:03:38.830 --> 00:03:42.850
不想查看整个列表

00:03:42.849 --> 00:03:45.069
并寻找哪个长度为 0

00:03:45.069 --> 00:03:47.439
我只是再次使用列表推导式

00:03:47.439 --> 00:03:48.855
循环访问所有内容

00:03:48.855 --> 00:03:50.384
我太喜欢推导式了

00:03:50.384 --> 00:03:54.819
我使用了列表推导式并进行这项测试

00:03:54.819 --> 00:03:58.629
确保每条影评的长度大于 0

00:03:58.629 --> 00:04:00.729
如果大于 0 就加上它

00:04:00.729 --> 00:04:05.319
否则不会添加到最终列表上

00:04:05.319 --> 00:04:07.819
也就是循环访问所有内容

00:04:07.819 --> 00:04:12.729
确保所有列表的长度大于 0

00:04:12.729 --> 00:04:14.949
我在这里构建了特征数组

00:04:14.949 --> 00:04:19.360
我认为这部分实际上很难

00:04:19.360 --> 00:04:21.045
肯定不简单

00:04:21.045 --> 00:04:22.170
并且可以通过多种方式实现

00:04:22.170 --> 00:04:25.720
如果这部分遇到问题的话 完全没关系

00:04:25.720 --> 00:04:27.449
你至少学到东西了 这就行了

00:04:27.449 --> 00:04:28.990
如果对你来说很难

00:04:28.990 --> 00:04:32.980
则表明你在学习知识 这正是我们对你的期望

00:04:32.980 --> 00:04:36.670
我首先

00:04:36.670 --> 00:04:40.927
初始化全为 0 的数组

00:04:40.927 --> 00:04:42.010
数组的长度表示影评的长度

00:04:42.009 --> 00:04:43.810
就像我提到的

00:04:43.810 --> 00:04:46.030
每条影评各占一行

00:04:46.029 --> 00:04:50.379
每行长为 200 个序列步长

00:04:50.379 --> 00:04:52.889
所以序列长度为 200

00:04:52.889 --> 00:04:56.099
特征数组的长度就等于

00:04:56.100 --> 00:04:59.760
影评的数量 乘以 影评序列长度

00:04:59.759 --> 00:05:01.800
这个告诉我们有多少条影评

00:05:01.800 --> 00:05:06.439
然后乘以 200 并且希望特征数组是整型

00:05:06.439 --> 00:05:10.709
有了 0 数组后 接下来我将填充这个0数组

00:05:10.709 --> 00:05:15.364
步骤很简单

00:05:15.365 --> 00:05:17.240
我们不需要左侧填充内容

00:05:17.240 --> 00:05:18.800
因为我们已经预设设好所有的值为0

00:05:18.800 --> 00:05:22.710
所以可以直接填充所需的元素

00:05:22.709 --> 00:05:25.079
我采取的方法是

00:05:25.079 --> 00:05:30.039
通过枚举法循环访问影评 即整数

00:05:30.040 --> 00:05:32.760
我使用这个枚举

00:05:32.759 --> 00:05:34.230
选择位于哪一行

00:05:34.230 --> 00:05:37.890
从特征中获取一行 例如行 i

00:05:37.889 --> 00:05:42.209
-len(row)

00:05:42.209 --> 00:05:46.769
如果行的长度小于 200

00:05:46.769 --> 00:05:49.889
例如是 100

00:05:49.889 --> 00:05:55.479
那么我将只拿走该行最后 100 个元素

00:05:55.480 --> 00:05:59.340
这就涵盖了影评单词数

00:05:59.339 --> 00:06:03.509
少于 200 的情况

00:06:03.509 --> 00:06:06.629
然后将影评中的每行

00:06:06.629 --> 00:06:09.509
转换为数组

00:06:09.509 --> 00:06:14.269
然后获取该数组中的前 200 个单词

00:06:14.269 --> 00:06:18.240
所以这里同时处理了我们会遇到的两种问题

00:06:18.240 --> 00:06:20.800
一种问题是

00:06:20.800 --> 00:06:22.300
如果影评超过 200 个单词

00:06:22.300 --> 00:06:23.879
如何获取前 200 个单词

00:06:23.879 --> 00:06:26.029
这部分就用来解决这一问题

00:06:26.029 --> 00:06:27.979
如果数组中的单词

00:06:27.980 --> 00:06:31.640
少于 200 个

00:06:31.639 --> 00:06:33.000
则如何将该数组添加到我们的数组后面？

00:06:33.000 --> 00:06:35.689
这部分就用来解决这一问题

00:06:35.689 --> 00:06:39.759
这是一种很简单的方式

00:06:39.759 --> 00:06:42.310
相信你可能采用了不同的方式

00:06:42.310 --> 00:06:45.759
当然也可以咯

00:06:45.759 --> 00:06:47.230
这只是我的方法

00:06:47.230 --> 00:06:50.259
我使用 NumPy 已经有很长时间了

00:06:50.259 --> 00:06:53.230
我可以通过经验知道如何实现很多功能

00:06:53.230 --> 00:06:54.840
例如这里提到的

00:06:54.839 --> 00:06:58.239
这就是编程的一般现象

00:06:58.240 --> 00:07:00.639
当你实践的次数越来越多

00:07:00.639 --> 00:07:04.539
就会学到各种技巧

00:07:04.540 --> 00:07:08.680
这样一些功能实现起来更快速 也更直观

00:07:08.680 --> 00:07:11.900
现在说说关于训练 验证和测试集

00:07:11.899 --> 00:07:14.039
我的解决方案

00:07:14.040 --> 00:07:16.220
差不多每次创建训练集等

00:07:16.220 --> 00:07:20.490
我都是采取这种类似的方法

00:07:20.490 --> 00:07:22.340
我定义了划分比例

00:07:22.339 --> 00:07:27.439
然后定义一些整数

00:07:27.439 --> 00:07:30.439
也就是从何处划分数据的索引

00:07:30.439 --> 00:07:33.230
这个需要设为整型

00:07:33.230 --> 00:07:35.660
因为要传入到数组中的索引

00:07:35.660 --> 00:07:38.890
必须是整型

00:07:38.889 --> 00:07:42.029
对于训练 x 和验证 x

00:07:42.029 --> 00:07:45.149
获取截止到划分索引的特征

00:07:45.149 --> 00:07:46.620
对于验证

00:07:46.620 --> 00:07:49.470
则从划分索引到结束

00:07:49.470 --> 00:07:53.320
对于训练 y 和验证 y

00:07:53.319 --> 00:07:53.819
则采取相同的流程

00:07:53.819 --> 00:07:56.550
并使用标签 而不是特征

00:07:56.550 --> 00:08:00.569
测试集几乎是相同的流程

00:08:00.569 --> 00:08:02.610
但是这里设为 0.5

00:08:02.610 --> 00:08:05.100
也就是查看验证集的长度

00:08:05.100 --> 00:08:09.000
并取一半的值 现在变成划分索引

00:08:09.000 --> 00:08:10.889
获取验证数据

00:08:10.889 --> 00:08:14.219
留下前半部分验证数据

00:08:14.220 --> 00:08:18.391
然后将另一半用作测试

00:08:18.889 --> 00:08:22.329
我在这里为输入 标签和保留概率

00:08:22.329 --> 00:08:26.139
创建了占位符

00:08:26.139 --> 00:08:27.279
很常见

00:08:27.279 --> 00:08:31.059
输入 tf.placeholder 这些将是整型

00:08:31.060 --> 00:08:33.480
然后将批次大小和序列大小

00:08:33.480 --> 00:08:38.230
变成变量 是任意值

00:08:38.230 --> 00:08:40.460
通常都可以

00:08:40.460 --> 00:08:42.870
对于标签

00:08:42.870 --> 00:08:46.200
我们每次只传递一个标签

00:08:46.200 --> 00:08:50.410
所以要么是 1 要么是 0

00:08:50.409 --> 00:08:53.279
在网络的稍后阶段 某些函数需要标签

00:08:53.279 --> 00:08:54.329
成为二维

00:08:54.330 --> 00:08:58.480
因此在这里设为二维

00:08:58.480 --> 00:09:00.359
这就要提到一种情况

00:09:00.359 --> 00:09:02.650
首先我将其设为一维 因为在我脑海中

00:09:02.649 --> 00:09:04.179
这个只需要一维就行

00:09:04.179 --> 00:09:06.370
然后 当我构建网络时

00:09:06.370 --> 00:09:09.460
我发现在某个地方调用函数时

00:09:09.460 --> 00:09:11.500
需要变成二维

00:09:11.500 --> 00:09:15.909
然后又回到这里

00:09:15.909 --> 00:09:19.240
重新创建这个标签占位符 并设为二维

00:09:19.240 --> 00:09:22.659
我发现经常遇到这种情况

00:09:22.659 --> 00:09:26.230
在 TensorFlow 中 到了某个阶段

00:09:26.230 --> 00:09:28.480
你之前定义的某些设置不可行

00:09:28.480 --> 00:09:30.820
因为形状或其他原因

00:09:30.820 --> 00:09:34.030
你会通过构建 TensorFlow 图表

00:09:34.029 --> 00:09:37.240
发现这种情况

00:09:37.809 --> 00:09:42.699
我在这里创建了嵌入层

00:09:42.700 --> 00:09:46.960
就像之前一样 例如 Word2Vec 网络

00:09:46.960 --> 00:09:50.590
将嵌入矩阵创建为变量

00:09:50.590 --> 00:09:53.530
这里我使用的是随机均匀分布

00:09:53.529 --> 00:09:56.709
大小是单词数量

00:09:56.710 --> 00:10:00.192
然后是嵌入大小 我设成了 300

00:10:00.192 --> 00:10:01.899
这样的话

00:10:01.899 --> 00:10:03.274
嵌入层级的输出长度

00:10:03.274 --> 00:10:05.649
将为 300 个单位

00:10:05.649 --> 00:10:08.699
将是长为 300 的向量

00:10:08.700 --> 00:10:13.070
每个传入的输入都是长 300 的向量

00:10:13.070 --> 00:10:16.490
因为实际上有

00:10:16.490 --> 00:10:21.560
多达 200 个单词输入进来

00:10:21.559 --> 00:10:25.399
这里是查询

00:10:25.399 --> 00:10:29.240
我们使用 tf.nn.embedding_lookup

00:10:29.240 --> 00:10:32.870
传入嵌入矩阵和输入

00:10:32.870 --> 00:10:37.139
然后获得嵌入向量

00:10:37.139 --> 00:10:41.370
我在这里创建了 LSTM 单元

00:10:41.370 --> 00:10:47.389
我创建了 BasicLSTMCell 设置大小

00:10:47.389 --> 00:10:51.789
然后对其应用 dropout 传入 LSTM 单元

00:10:51.789 --> 00:10:55.029
设置保留概率

00:10:55.029 --> 00:11:02.480
将这个传入 MultiRNNCell 然后获取初始状态

00:11:02.480 --> 00:11:04.460
这是前向传播

00:11:04.460 --> 00:11:06.970
这里我使用了 dynamic_rnn

00:11:06.970 --> 00:11:08.389
然后传入创建的单元

00:11:08.389 --> 00:11:12.199
这是嵌入层级的输出

00:11:12.200 --> 00:11:14.100
然后是输入状态

00:11:14.100 --> 00:11:17.610
然后就得出最后状态的

00:11:17.610 --> 00:11:19.100
LSTM 单元的输出

00:11:22.299 --> 00:11:24.549
这就是构建完毕和

00:11:24.549 --> 00:11:26.049
训练之后的状态

00:11:29.200 --> 00:11:31.900
只要 25 个批次

00:11:31.899 --> 00:11:36.459
很快验证集的准确率

00:11:36.460 --> 00:11:37.650
就几乎达到 71%

00:11:37.649 --> 00:11:39.069
然后再经历一些批次

00:11:39.070 --> 00:11:43.810
最终达到 83% 左右

00:11:43.809 --> 00:11:47.079
噢耶 这里是 84 最后变成 83

00:11:47.080 --> 00:11:52.370
效果很棒 训练速度很快

00:11:52.370 --> 00:11:55.279
在 GPU 上很快

00:11:55.279 --> 00:11:59.689
对于测试准确性 大概为 83%

00:11:59.690 --> 00:12:03.410
如果向 LSTM 单元中添加更多层级或更多单元

00:12:03.409 --> 00:12:08.120
那么准确性可能更高

00:12:08.120 --> 00:12:11.330
或者也许我们的数据集

00:12:11.330 --> 00:12:14.270
就只能到这个程度了

00:12:14.269 --> 00:12:17.000
希望你喜欢这节课

00:12:17.000 --> 00:12:20.730
喜欢实现情感分析

00:12:20.730 --> 00:12:23.360
或情感预测循环神经网络

00:12:23.360 --> 00:12:25.519
下节课再见

00:12:25.519 --> 00:12:27.069
加油

