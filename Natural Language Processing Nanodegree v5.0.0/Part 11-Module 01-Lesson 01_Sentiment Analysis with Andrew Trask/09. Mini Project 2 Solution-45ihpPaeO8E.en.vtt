WEBVTT
Kind: captions
Language: en

00:00:00.100 --> 00:00:02.360
Right, so in this project we're going
to create our input and output data.

00:00:02.360 --> 00:00:05.903
So, for input data, we're going to count
all the words that happen in a review,

00:00:05.903 --> 00:00:08.320
and then we're going to put them
into a fixed length vector.

00:00:08.320 --> 00:00:12.170
Where each place in the vector is for
one of our words of our vocabulary.

00:00:12.170 --> 00:00:14.375
So the first thing we do
is we count our vocabulary.

00:00:14.375 --> 00:00:17.890
Looks like we have
just over 74,000 words.

00:00:17.890 --> 00:00:19.960
Now we're going to
create our empty vector.

00:00:19.960 --> 00:00:23.650
Now it's generally a good practice
to pre-allocate this vector

00:00:23.650 --> 00:00:26.290
as just something that's empty and
then edit it as you go.

00:00:26.290 --> 00:00:28.990
Because one of those expensive
things you can do in

00:00:28.990 --> 00:00:30.660
computer science is allocate new memory.

00:00:30.660 --> 00:00:33.487
So we don't want to have to create this
new vector from scratch every time that

00:00:33.487 --> 00:00:33.886
we use it.

00:00:33.886 --> 00:00:36.988
So we're going to create an empty one
and then we're going to createa function

00:00:36.988 --> 00:00:39.020
that modifies this vector
with the proper counts.

00:00:40.140 --> 00:00:43.860
So, first thing we need to do is decide
which place in this vector goes to each

00:00:43.860 --> 00:00:46.695
word, and create a variable that
allows us to research that.

00:00:46.695 --> 00:00:49.759
Now, it doesn't really matter which
place that we put it in, it's like,

00:00:49.759 --> 00:00:51.767
horrible can be down here,
or it could up there.

00:00:51.767 --> 00:00:55.320
But as long as whatever we choose
we kind of stick with, right?

00:00:55.320 --> 00:00:59.390
So I'm going to create just a dictionary
that allows us to look up every

00:00:59.390 --> 00:01:03.040
word that's in our vocabulary according
to the place that it has in that

00:01:03.040 --> 00:01:03.350
vocabulary.

00:01:03.350 --> 00:01:05.200
And then we're going to
create our function.

00:01:05.200 --> 00:01:06.670
So layer here the global variable.

00:01:06.670 --> 00:01:08.130
We're going to clear out the old ones.

00:01:08.130 --> 00:01:12.850
Then we're going to iterate
through each word in our review.

00:01:12.850 --> 00:01:17.876
And we're going to allocate the position
in that vector where we're incrementing,

00:01:17.876 --> 00:01:20.125
so that there's a count for each one.

00:01:20.125 --> 00:01:24.723
Then we tried out in the first review,
for the review 0 was this, right?

00:01:24.723 --> 00:01:25.640
And it looks like it worked.

00:01:25.640 --> 00:01:29.814
Actually one of the words, presumably
the empty one when I tokenized it,

00:01:29.814 --> 00:01:31.103
happened 18 times.

00:01:31.103 --> 00:01:32.496
How about that?

00:01:32.496 --> 00:01:37.097
So get_target_for_label seems to work,
so

00:01:37.097 --> 00:01:43.658
label(0) was positive, and
label(1) I think was negative.

00:01:43.658 --> 00:01:45.115
So yeah,
it looks like it's working great.

00:01:45.115 --> 00:01:46.470
S this will work great for us.

00:01:46.470 --> 00:01:48.499
This is our input and output dataset and

00:01:48.499 --> 00:01:52.077
I hope that yours created kind of
variables that look a lot like this.

00:01:52.077 --> 00:01:54.935
The nice what we're doing here is,
and I guess the thing to take away,

00:01:54.935 --> 00:01:56.690
is mostly this efficiency piece, right?

00:01:56.690 --> 00:01:59.050
So when you're creating these vectors,

00:01:59.050 --> 00:02:01.790
try not to allocate completely
new vectors for your data.

00:02:01.790 --> 00:02:05.590
The second thing that we're also not
doing is pre-generating the entire

00:02:05.590 --> 00:02:06.577
data set, right?

00:02:06.577 --> 00:02:12.440
because that would be a matrix that is
74,000 by, how many train examples?

00:02:12.440 --> 00:02:19.336
25,000, so 74,000 vocab_size x 25,000,

00:02:19.336 --> 00:02:25.220
that would be,
man [LAUGH] around 2 billion integers.

00:02:25.220 --> 00:02:28.993
Which is just, that's a lot of stuff to
store on your machine when, in reality,

00:02:28.993 --> 00:02:30.722
we can populate this pretty easily.

00:02:30.722 --> 00:02:33.650
And most of them are zeroes, and they're
pretty quick we need to generate.

00:02:33.650 --> 00:02:35.620
So this is just generally
good practice for

00:02:35.620 --> 00:02:39.310
creating your data set without
filling up your RAM on your laptop.

00:02:39.310 --> 00:02:41.350
So, that's our input and
output data set.

00:02:41.350 --> 00:02:42.820
Those are kind of the things
to watch out for.

00:02:42.820 --> 00:02:44.790
Don't allocate too much memory at once,

00:02:44.790 --> 00:02:46.997
and don't create new
variables all the time.

00:02:46.997 --> 00:02:49.604
These are forms that we're going
to use in our neural net, right?

00:02:49.604 --> 00:02:51.764
So in the next section we're going to
be talking about how we're going to put

00:02:51.764 --> 00:02:52.990
this together into our neural network.

00:02:52.990 --> 00:02:53.480
See you there.

