WEBVTT
Kind: captions
Language: zh-CN

00:00:00.440 --> 00:00:01.700
让我们首先来整理一个数据集

00:00:03.060 --> 00:00:06.589
神经网络本身不能做任何事

00:00:06.589 --> 00:00:08.960
神经网络所做的唯一的事情就是

00:00:08.960 --> 00:00:11.250
搜索两个数据集之间直接或间接的相关性

00:00:11.250 --> 00:00:13.839
因此 为了让神经网络来做训练

00:00:13.839 --> 00:00:16.750
我们需要给它提供 2 个有意义的数据集

00:00:16.750 --> 00:00:19.109
第一个数据集 必须代表我们已知的信息

00:00:19.109 --> 00:00:21.875
第二个数据集 必须代表我们想要知道的信息

00:00:21.875 --> 00:00:24.620
我们想要神经网络告诉我们什么答案

00:00:24.620 --> 00:00:27.650
随着网络不断训练 它将不断寻找两组数据集之间的相关性

00:00:27.649 --> 00:00:31.289
最终能够根据一组的输入 预测另一组的值

00:00:31.289 --> 00:00:35.140
下面 我将用我们数据集的例子为大家说明

00:00:35.140 --> 00:00:39.700
在这里 我们将载入一组 IMDB 的电影评论

00:00:39.700 --> 00:00:42.640
这些都是人们上传到 IMDB 网站的电影评论

00:00:43.750 --> 00:00:47.270
这些标签与评论一一对应

00:00:47.270 --> 00:00:49.660
人们给电影从一星到五星打分

00:00:49.659 --> 00:00:53.769
在这里 我们简化成了正面评价：高于三星

00:00:53.770 --> 00:00:56.750
负面评价：低于三星

00:00:56.750 --> 00:00:58.079
因此 我们这里有 25000 条评论

00:00:58.079 --> 00:01:03.917
这里是一条负面评价的例子

00:01:03.917 --> 00:01:04.679
嗯 是的

00:01:04.680 --> 00:01:09.690
然后 这一条 我们可以看到 它是一条正面评价

00:01:09.689 --> 00:01:11.870
标签也显示为 正面的标签

00:01:11.870 --> 00:01:13.439
所以 这就是我们的数据集

00:01:13.439 --> 00:01:14.789
事实上是两个数据集 对吧？

00:01:14.790 --> 00:01:17.230
因此 我们有了这组数据代表我们所知道的信息

00:01:17.230 --> 00:01:18.810
以及这一组 我们想要预测的数据 对吧？

00:01:18.810 --> 00:01:20.829
然后 这就是我们想要从数据集中了解的

00:01:20.829 --> 00:01:23.361
这个例子中 我们有两个数据集样本

00:01:23.361 --> 00:01:26.609
我们要训练一个神经网络 将这些作为输入

00:01:26.609 --> 00:01:28.790
然后能准确地预测这个

00:01:28.790 --> 00:01:33.920
这样 未来我们看到更多人类生成的文本 从理论上讲

00:01:33.920 --> 00:01:35.260
我们的神经网络将能够进行分类

00:01:36.609 --> 00:01:39.150
我们拿到这样一个数据集 要做的第一件事

00:01:39.150 --> 00:01:40.990
就是建立出一个预测理论

00:01:40.989 --> 00:01:44.929
预测理论实际上来说就是… 好 假设我是神经网络

00:01:44.930 --> 00:01:48.720
我试图找到一个方法

00:01:48.719 --> 00:01:51.340
来发现数据集中的相关性 我会从哪里找？

00:01:51.340 --> 00:01:55.150
我在构建预测理论时最喜欢做的就是

00:01:55.150 --> 00:01:56.280
看看数据集

00:01:56.280 --> 00:01:58.989
看看我自己是否能解决这个问题

00:01:58.989 --> 00:02:00.519
然后就反躬自省

00:02:00.519 --> 00:02:05.949
我现在用的方法可能可以区分

00:02:05.950 --> 00:02:08.669
这是否有正面或负面的情绪

00:02:08.669 --> 00:02:10.150
所以 让我们先来读几条电影评论吧

00:02:10.150 --> 00:02:13.289
“这部电影太糟糕了 但特效还可以”

00:02:13.289 --> 00:02:17.229
刚才这条是负面评论 “Adrian Pasdar 在影片中表现棒极了”

00:02:17.229 --> 00:02:19.379
“他扮的女人很迷人”

00:02:19.379 --> 00:02:23.699
负面评价 “这部电影怎么拍出来的！太烂了！”

00:02:23.699 --> 00:02:25.780
“完全不合逻辑 前后说不通”

00:02:25.780 --> 00:02:29.599
正面评价 “非常棒的一部类似《低俗小说》的剧集式电影 7 天 7 次自杀” (注：原影评为 "7 days 7 suicides" 可能数字在抓取词库时被过滤了)

00:02:29.599 --> 00:02:31.250
“它并没有…”  然后一条接着一条

00:02:32.280 --> 00:02:34.650
所以 读了之后 我已经有一种感觉

00:02:34.650 --> 00:02:39.349
对我来说 这些都是倾向性非常明显的评论

00:02:39.349 --> 00:02:42.389
但我要寻找的是

00:02:42.389 --> 00:02:46.459
究竟什么在评论数据集和标签数据集之间建立起了相关性

00:02:47.770 --> 00:02:49.689
相关性究竟来自什么？

00:02:49.689 --> 00:02:51.169
这是一个字符的列表 对吗？

00:02:51.169 --> 00:02:55.409
所以 当我实际加载它 它本地的格式

00:02:55.409 --> 00:02:58.799
只是 26+ 的不同字符组合

00:03:00.129 --> 00:03:02.090
目前情况下是否存在相关性？

00:03:02.090 --> 00:03:07.390
我认为 字母 M 或字母 T 并不具备太强的预测能力

00:03:07.389 --> 00:03:11.919
我们在负面评价中有 M 在正面评价中也有 M

00:03:11.919 --> 00:03:15.139
它并没有帮到我们 所以我不认为这是一个很好的来源

00:03:15.139 --> 00:03:18.809
所以 这些字符并不是一个很好的预测源

00:03:18.810 --> 00:03:21.550
现在 我们换一种方式考虑

00:03:21.550 --> 00:03:26.610
我们将整条评论作为一个数据源

00:03:26.610 --> 00:03:29.100
那么 它就有很强的预测性了

00:03:29.099 --> 00:03:33.819
我是指 我们每次看到这条评论时 都会判定它是负面评价的例子

00:03:33.819 --> 00:03:35.509
遗憾的是 我们只会看到它一次

00:03:35.509 --> 00:03:38.359
我认为我们可以预期 将来看到的大多数评论

00:03:38.360 --> 00:03:40.220
都会是相对原创的

00:03:40.219 --> 00:03:42.500
我们会看到有些人说 这部电影太糟糕了

00:03:42.500 --> 00:03:45.349
或者这部电影太棒了 或者真的很直接 类似的话

00:03:45.349 --> 00:03:47.442
但大多数评论有细微差别

00:03:47.442 --> 00:03:50.990
他们的遣词造句

00:03:50.990 --> 00:03:54.300
都有个性 不是会经常重复出现的

00:03:54.300 --> 00:03:57.903
所以 如果针对整条评论来训练神经网络 实际效果不会太好

00:03:57.902 --> 00:04:00.689
因为现实世界中 同样的评论并不经常出现

00:04:00.689 --> 00:04:03.520
所以 相关性很大 但泛化性差

00:04:04.520 --> 00:04:06.909
那么我们在字符和整条评论之间折中呢？

00:04:06.909 --> 00:04:12.164
我注意到 在负面评论中 经常出现一些词 比如 terrible (可怕的)、

00:04:12.164 --> 00:04:19.060
improbable (不可能的)、terrible、terrible 和 trash (垃圾)

00:04:20.600 --> 00:04:25.100
还有个别词 可能与这些正面和负面标签有一定相关性

00:04:25.100 --> 00:04:30.460
相反的词有 excellent (优秀的)、fascinating (迷人的) 或 excellent quality (优秀的品质)

00:04:30.459 --> 00:04:35.659
因此 可能只是不同词出现次数的计数

00:04:35.660 --> 00:04:38.020
它们在评论里出现了多少次

00:04:38.019 --> 00:04:41.250
我认为 这是一种更好的理论

00:04:41.250 --> 00:04:42.550
肯定比字符更好

00:04:42.550 --> 00:04:45.199
也肯定比整条评论作为一个整体要好

00:04:45.199 --> 00:04:47.860
但在我们草草建立一个神经网络前

00:04:47.860 --> 00:04:50.850
我认为我们最好做一个快速的验证 对吧？

00:04:50.850 --> 00:04:56.410
这是我们认为正确的理论

00:04:56.410 --> 00:04:57.820
在我们正式开始之前

00:04:57.819 --> 00:05:03.509
我们要看一下 我们的预测是否真的奏效 对吧？

00:05:03.509 --> 00:05:06.449
这里 我通常做的只是 数一数次数

00:05:06.449 --> 00:05:11.500
或者说 我设定了基于计数的启发式尝试 来看看

00:05:11.500 --> 00:05:16.855
这一现象在这种标签上的出现频率是否要高于那一种标签？

00:05:16.855 --> 00:05:18.764
这是一个很好的标签分类器

00:05:18.764 --> 00:05:21.230
所以 我要大家做第一个项目

00:05:21.230 --> 00:05:25.930
然后我会告诉大家 我是怎么解决的 第一个项目就是想一想

00:05:25.930 --> 00:05:30.590
你会如何处理数据集 然后验证我们的理论是可以给出正确的预测

00:05:31.740 --> 00:05:35.420
好了 去做吧 花几分钟来解决它 看看能否

00:05:35.420 --> 00:05:39.949
找到一种方法 来显示 “具有” 或 “不具有” 预测性

