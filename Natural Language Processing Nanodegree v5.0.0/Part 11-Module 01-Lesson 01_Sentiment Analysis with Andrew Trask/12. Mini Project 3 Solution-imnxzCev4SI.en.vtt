WEBVTT
Kind: captions
Language: en

00:00:00.340 --> 00:00:03.520
All right, so in project three we're
going to build our neural network.

00:00:03.520 --> 00:00:06.220
That is going to predict whether or
not a neural review has positive or

00:00:06.220 --> 00:00:11.150
negative sediment by using the counts
of words that are inside of our review.

00:00:11.150 --> 00:00:15.120
Now the changes I made first were, to
create a pre process data function, that

00:00:15.120 --> 00:00:18.320
just brings in all the kind of little
snippets that we built and tested above.

00:00:18.320 --> 00:00:23.330
So word to index, kind of the different
vocabularies, and vocabulary sizes.

00:00:23.330 --> 00:00:26.140
Just all of the variables that
we used in our training dataset

00:00:26.140 --> 00:00:28.750
generation logic, I wanted to have it
in a pre-processing data function,

00:00:28.750 --> 00:00:33.280
so that it's all kind of self contained
in the variables that are in this class.

00:00:33.280 --> 00:00:35.960
The next thing I did was, I split off
the stuff that was in here into an init

00:00:35.960 --> 00:00:38.350
network function,
just to keep things clean, and

00:00:38.350 --> 00:00:43.340
also this needs to know the number of
input nodes, the number of output nodes.

00:00:43.340 --> 00:00:47.640
Which is based on the number of reviews
or unique vocabulary in our views, and

00:00:47.640 --> 00:00:49.490
the number of labels that we have.

00:00:49.490 --> 00:00:52.900
So it's nice to kind of have
these in separate function,

00:00:52.900 --> 00:00:55.970
just so that you can kind of read
the progress that's here, and

00:00:55.970 --> 00:00:58.600
just clean it that way,
I kind of like it.

00:00:58.600 --> 00:01:01.214
And the next thing it did was update
input layer and set target for

00:01:01.214 --> 00:01:03.696
label which are these functions
that we played with before.

00:01:03.696 --> 00:01:05.975
I'm going to go ahead and
move into the class just so

00:01:05.975 --> 00:01:08.307
that it's all kind of self contained and
together,

00:01:08.307 --> 00:01:11.490
and that makes this class portable,
so I can use it somewhere else.

00:01:11.490 --> 00:01:11.960
All right, so

00:01:11.960 --> 00:01:14.440
now on the training method, this is
where most of the action is, right?

00:01:14.440 --> 00:01:16.900
So the first thing I checked was that,

00:01:16.900 --> 00:01:20.050
the number of training reviews we have
is the same as the number of labels.

00:01:20.050 --> 00:01:22.770
So in the off chance someone
input something that

00:01:22.770 --> 00:01:25.520
doesn't line up correctly,
we kind of want to let people know,

00:01:25.520 --> 00:01:29.140
so we see a kind of weird
behavior in around that.

00:01:29.140 --> 00:01:31.548
And the next thing we´re going to do
is kind of intialize correct so far,

00:01:31.548 --> 00:01:33.639
we´re going keep track of how
many predictions we get right and

00:01:33.639 --> 00:01:34.680
wrong while we´re training.

00:01:34.680 --> 00:01:37.860
This is a useful metric that I kind
of like to watch to understand

00:01:37.860 --> 00:01:41.100
how the neuromet is doing during
the training process, right.

00:01:41.100 --> 00:01:45.350
Is it getting better, is it not getting
better at all, is it getting worse?

00:01:45.350 --> 00:01:49.250
These things are kind of the basics
of understanding how you're doing and

00:01:49.250 --> 00:01:51.620
then being able to adjust for that.

00:01:51.620 --> 00:01:53.500
Now also we select review and

00:01:53.500 --> 00:01:56.370
a label out of our training reviews,
we update the input layer.

00:01:56.370 --> 00:02:00.280
This is the same as previously we were
propagating from layer zero to layer

00:02:00.280 --> 00:02:02.840
one, or from your input
layer to your hidden layer.

00:02:02.840 --> 00:02:07.100
However, in this case,
we have to adjust and

00:02:07.100 --> 00:02:10.949
generate our input data set first
before we can do this propagation.

00:02:10.949 --> 00:02:14.330
So now we generate hidden layer same way
as before, except without nonlinearity,

00:02:14.330 --> 00:02:17.100
and the last one will
generate with nonlinearity.

00:02:17.100 --> 00:02:19.940
So that's our forward propagation step.

00:02:19.940 --> 00:02:22.690
Our back propagation step,
the first thing we do.

00:02:22.690 --> 00:02:24.565
How close did we, did we miss?

00:02:24.565 --> 00:02:26.490
This is where we put our
function that we created.

00:02:26.490 --> 00:02:31.519
We say our prediction minus our
function, and then because we

00:02:31.519 --> 00:02:36.935
have a nonlinearity on this layer
our layer 2 delta has to multiply

00:02:36.935 --> 00:02:41.883
by this function,
which is sigmoid times 1 minus sigmoid.

00:02:41.883 --> 00:02:42.640
And then we continue to
back propagate in this way.

00:02:42.640 --> 00:02:46.490
Now a thing that you see we skip here is
that because there's a nonlinearity on

00:02:46.490 --> 00:02:51.470
layer one, we don't do this
multiplication step here, unlike before,

00:02:51.470 --> 00:02:53.060
because this is a linear layer.

00:02:53.060 --> 00:02:58.134
So we don't actually have to adjust for
the not mislope of the non linearity.

00:02:58.134 --> 00:03:00.431
Once we have our layer two and
layer one deltas,

00:03:00.431 --> 00:03:02.220
we're ready to update our weights.

00:03:02.220 --> 00:03:04.850
Which you do here in the exact same
way that we did in our previous

00:03:04.850 --> 00:03:05.900
neural network.

00:03:05.900 --> 00:03:09.880
And then add a little bit of logic
just to kind of log our progress.

00:03:09.880 --> 00:03:14.450
As well as see how fast we're training,
and how many predictions we got correct.

00:03:14.450 --> 00:03:18.230
Now how am I deciding whether
we got something correct or not?

00:03:18.230 --> 00:03:22.100
What I'm looking at is the absolute
value of our prediction, or,

00:03:22.100 --> 00:03:24.280
excuse me, the absolute value
of the error of our prediction.

00:03:24.280 --> 00:03:27.785
So up here we calculate the difference
between what our prediction

00:03:27.785 --> 00:03:29.170
should be and what it was.

00:03:29.170 --> 00:03:32.527
And so I said if it predicts
exactly 0.5, well it didn't,

00:03:32.527 --> 00:03:34.210
it's totally ambiguous.

00:03:34.210 --> 00:03:38.378
It's kind of half way between positive
and negative, it didn't pick either.

00:03:38.378 --> 00:03:42.596
But if it's closer to
the right prediction,

00:03:42.596 --> 00:03:47.710
well then this error measure
will be less than 0.5.

00:03:47.710 --> 00:03:52.252
And so that's why I can kind of see
how many classifications we got right,

00:03:52.252 --> 00:03:56.426
as opposed to just the loss by kind
of just typing this on the fly, and

00:03:56.426 --> 00:03:57.830
then logging as we go.

00:03:59.380 --> 00:04:02.520
Now the other thing I want to
be able to do here is test it.

00:04:02.520 --> 00:04:06.140
Which is really just a matter
of taking it for logic and

00:04:06.140 --> 00:04:09.870
in the evaluation logic, put that in
a one function, which I did here.

00:04:09.870 --> 00:04:14.300
And then I add another one for running
where we can put in a text review and

00:04:14.300 --> 00:04:17.300
it converts that text into an input
data, and just forward pops and

00:04:17.300 --> 00:04:18.519
give POSITIVE, NEGATIVE labels.

00:04:18.519 --> 00:04:20.589
So we can test it on
the whole data set or

00:04:20.589 --> 00:04:24.690
we can kind of throw in some
examples and see whether we like it.

00:04:24.690 --> 00:04:28.930
So now that we've got this,
let's go ahead and

00:04:28.930 --> 00:04:33.510
first validate that our and
the next we'd go first and create one.

00:04:34.650 --> 00:04:37.728
Here, I'm actually selecting
the first 24,000 reviews to train on.

00:04:37.728 --> 00:04:39.300
And I'm just going ahead and say it,

00:04:39.300 --> 00:04:46.600
the last we could say these 1,000
reviews can be our test data set.

00:04:46.600 --> 00:04:48.130
So I'm going to kind of
continue to do that.

00:04:48.130 --> 00:04:50.230
You could pick a different
training test split,

00:04:50.230 --> 00:04:53.940
there's actually another 25,000 in
the IMDB data set you could use.

00:04:53.940 --> 00:04:55.400
But, just for
the sake of making it easy,

00:04:55.400 --> 00:04:58.250
I think we're just
going to go with this.

00:04:58.250 --> 00:05:00.010
So, we're going to
initialize it this way,

00:05:00.010 --> 00:05:02.160
this is actually our
default learning rate.

00:05:02.160 --> 00:05:07.140
&gt;From here, I'm going to put it in so
just we can see it.

00:05:07.140 --> 00:05:10.400
The other thing I like to do before
we get started is actually test it.

00:05:10.400 --> 00:05:13.100
So our waits are initialized
randomly right now, so

00:05:13.100 --> 00:05:16.880
it shouldn't really predict well at all.

00:05:16.880 --> 00:05:20.940
So in this case, testing
accuracy is exactly 50% which is,

00:05:20.940 --> 00:05:25.390
if you just guessed, between
positive and negative randomly then

00:05:25.390 --> 00:05:28.160
gear you should get 50% accuracy,
and it's actually what we see here.

00:05:28.160 --> 00:05:31.970
Which is a good place to start.\
Especially when you have a neural

00:05:31.970 --> 00:05:33.800
net with only two predictions,

00:05:33.800 --> 00:05:37.470
I really like to see it start off
not being biased towards one way.

00:05:37.470 --> 00:05:41.889
Like if I initialize my weights in such
a way where it always predicts one way

00:05:41.889 --> 00:05:45.830
or always predicts another, or
it doesn't get any of them right.

00:05:45.830 --> 00:05:47.620
Then I kind of scratch my head like,
wait a minute,

00:05:47.620 --> 00:05:51.690
something's probably broken here, and
so I'll go investigate that first.

00:05:51.690 --> 00:05:55.390
But, as we can see,
it's breaking randomly, and

00:05:55.390 --> 00:05:59.820
it doesn't seem to have any real
predictive power at the moment.

00:05:59.820 --> 00:06:02.100
So, now we're going to
try to train our network.

00:06:04.290 --> 00:06:07.280
Every, something I threw in here
a little bit later is that,

00:06:07.280 --> 00:06:10.510
every 2,500 predictions it will do
a new line, wo we can not just see

00:06:10.510 --> 00:06:15.200
what the progress is now but,
we can kind of see it change over time.

00:06:16.560 --> 00:06:18.910
So now when I'm watching it train
there's a few things I'm looking at.

00:06:18.910 --> 00:06:23.520
First is speed, trying to kind of gauge,
how long am I going to be sitting here?

00:06:23.520 --> 00:06:26.124
And then I'm also looking
at the training accuracy.

00:06:26.124 --> 00:06:31.081
So now if you look, so far it's actually
not predicting particularly well.

00:06:31.081 --> 00:06:33.910
It's doing just worse than random.

00:06:33.910 --> 00:06:37.140
Which is sort of worse
than it was doing before.

00:06:37.140 --> 00:06:40.990
At this point, when we're 14% of the way
through the training data set, and

00:06:40.990 --> 00:06:45.330
it hasn't even learned anything yet, and
it’s like it is doing worst then that.

00:06:45.330 --> 00:06:48.020
I’m really starting to go okay,
something is probably wrong here.

00:06:48.020 --> 00:06:52.380
They are a few types of neutral nets
where at this point it actually

00:06:52.380 --> 00:06:55.470
does continue print random especially
in reinforcement learning,

00:06:55.470 --> 00:06:58.630
however on this dataset we
are looking in direct correlation.

00:06:58.630 --> 00:07:03.518
I should be seeing some change right
here, so I’m just going to go ahead

00:07:03.518 --> 00:07:08.486
a quit this out, we could wait longer,
but I just don't think that it's

00:07:08.486 --> 00:07:13.225
going to be a good idea to do that, so
we're going to go ahead and hit stop.

00:07:13.225 --> 00:07:15.613
The natural thing for
me to do here is think, okay, so

00:07:15.613 --> 00:07:17.430
the learning rate's too high, right?

00:07:17.430 --> 00:07:21.655
So, when things are doing like this,
maybe it's diverging, who knows.

00:07:21.655 --> 00:07:24.138
So let's go ahead and
adjust this learning rate to b.

00:07:24.138 --> 00:07:30.352
Lower and a good way to fill things out
is first move by orders in magnitude so

00:07:30.352 --> 00:07:35.088
I'm going to divide it by ten,
reinitialize the network,

00:07:35.088 --> 00:07:40.218
I'm queue slash then compare
bounce around a little bit Man,

00:07:40.218 --> 00:07:44.090
I'm starting to see
kind of the same behavior.

00:07:44.090 --> 00:07:45.610
It's not really getting better.

00:07:45.610 --> 00:07:47.060
Now we'll just train for a second and

00:07:47.060 --> 00:07:50.010
then kind of talk about why
was I lowering rate, right?

00:07:50.010 --> 00:07:54.160
So lowering rate, if you remember
from before, is the step side,

00:07:54.160 --> 00:07:57.520
it's how big of a jump that it
tries to take to reduce the error.

00:07:58.720 --> 00:08:02.810
Probably a standard reason why
thins kind of thing happens is that

00:08:02.810 --> 00:08:06.790
it's over shooting, so
it's ending up not really any closer

00:08:07.990 --> 00:08:12.170
to solving the problem than when it
started because it's going to far.

00:08:12.170 --> 00:08:15.954
Under shooting means the network
trains very very slowly but

00:08:15.954 --> 00:08:20.404
it does tend to make progress, this
to me could be very very slowly, but

00:08:20.404 --> 00:08:23.691
it just doesn't look like it's,
training at all.

00:08:23.691 --> 00:08:27.610
It's just camping out right near 50% and
so that's really concerning.

00:08:27.610 --> 00:08:31.182
And so, we're at our 20% here, I should
be seeing something at this point.

00:08:31.182 --> 00:08:34.524
So we're going to cancel this and
we're going to go again.

00:08:34.524 --> 00:08:36.873
So check this out.

00:08:36.873 --> 00:08:37.820
Do it one more time.

00:08:37.820 --> 00:08:40.283
[BLANK_AUDIO]

00:08:40.283 --> 00:08:41.933
Okay, camping out 40%

00:08:41.933 --> 00:08:43.826
[BLANK_AUDIO]

00:08:43.826 --> 00:08:46.533
Create.

00:08:46.533 --> 00:08:47.482
Come on, buddy.

00:08:47.482 --> 00:08:48.450
It's funny.

00:08:48.450 --> 00:08:54.280
Eventually, these types of metrics
become really entertaining to watch.

00:08:54.280 --> 00:08:57.710
And man, I'm actually still kind of
surprised, it is not really happening.

00:08:59.120 --> 00:09:02.510
Here we go, okay, so
it's starting to learn a little bit,

00:09:02.510 --> 00:09:03.810
so this is a good sign, right?

00:09:03.810 --> 00:09:07.850
So it's starting to find correlation but
it's still going pretty slow, not only,

00:09:07.850 --> 00:09:10.870
like this is pretty slow as
far as your views per second.

00:09:10.870 --> 00:09:13.610
It's only expressing 100
reviews per second but

00:09:13.610 --> 00:09:16.840
then it's not converting very quickly,
right?

00:09:16.840 --> 00:09:18.980
And I can keep knocking
down the learning rate, but

00:09:18.980 --> 00:09:21.730
the truth is, the more you
knock down the learning rate,

00:09:21.730 --> 00:09:23.410
the slower the learning happens, right?

00:09:23.410 --> 00:09:26.960
Whereas before, overshooting, this is
still going to continue knocking down.

00:09:26.960 --> 00:09:30.110
So one thing that I could do here is
continue to tweak the learning rate,

00:09:30.110 --> 00:09:31.900
and I could spend all day
trying to do that, and

00:09:31.900 --> 00:09:34.060
I would get incremental Improvements.

00:09:34.060 --> 00:09:39.170
But we're so early on we haven't
refined anything, just pose some big

00:09:39.170 --> 00:09:43.660
frame questions that we need to really
re-evaluate in our neural networks.

00:09:43.660 --> 00:09:45.030
Say hey, can we frame this problem so

00:09:45.030 --> 00:09:47.810
that the correlation is
a little more clear, right?

00:09:47.810 --> 00:09:51.150
So right now I'm going back,
I'm thinking, okay, so, up here.

00:09:51.150 --> 00:09:55.080
This is our setup, right, we're counting
the words and putting them in here, and

00:09:55.080 --> 00:09:57.450
then it's making a prediction.

00:09:57.450 --> 00:10:01.990
What about this is so difficult for
this thing that it's taking this,

00:10:01.990 --> 00:10:06.350
so it is converging, but
it's just not going very quickly.

00:10:06.350 --> 00:10:12.040
Is there anything that we can do, to
make it more obvious for the network for

00:10:12.040 --> 00:10:15.960
it to identify the words that
were validated in kind of in our,

00:10:15.960 --> 00:10:18.790
well not those lists those
were the raw counts.

00:10:18.790 --> 00:10:22.800
Up here, right so
it finds these words more easily, so

00:10:22.800 --> 00:10:25.420
there are two things
that I typically do here.

00:10:25.420 --> 00:10:29.600
One is I start changing stuff and see if
stuff works, and the other one is I dig

00:10:29.600 --> 00:10:34.290
deeper in to exactly what's going here,
take a look at a few training examples.

00:10:34.290 --> 00:10:38.180
See that, make sure that the pattern
that I think should be in there is

00:10:38.180 --> 00:10:41.570
actually showing up or
maybe I have a mistake in my logic.

00:10:41.570 --> 00:10:44.500
Nine times out of ten, when something's
not training correctly it means

00:10:44.500 --> 00:10:47.040
that there's something simple
in here that I got backwards,

00:10:47.040 --> 00:10:48.800
more than a big complicated change.

00:10:48.800 --> 00:10:51.730
But sometimes it needs
to be a big complicated

00:10:51.730 --> 00:10:55.750
change, it's still training
really really quickly.

00:10:55.750 --> 00:10:59.030
So I mean if we if we extrapolated
this you know things can

00:10:59.030 --> 00:11:01.770
train fast in the beginning and
then slow down and taper off.

00:11:01.770 --> 00:11:05.225
So I mean I don't really see
this getting much past 61, 62,

00:11:05.225 --> 00:11:11.180
something in that kind of range,
I don't know if they keep training.

00:11:11.180 --> 00:11:13.119
All right.

00:11:13.119 --> 00:11:14.150
So now I'm going to ask my question.

00:11:14.150 --> 00:11:14.237
Okay.

00:11:14.237 --> 00:11:15.400
How can I make this simpler?

00:11:16.600 --> 00:11:19.050
What is the signal in my training data,

00:11:19.050 --> 00:11:21.150
and what is the noise
in my training data?

00:11:22.360 --> 00:11:27.320
And that's going to be kind of a topic
of the next section, which we're going

00:11:27.320 --> 00:11:30.410
to analyze, and then try to see if we
can get this training to happen faster.

00:11:30.410 --> 00:11:32.170
So feel free to let this
kind of train all the way,

00:11:32.170 --> 00:11:34.760
I don't think it'll get
too much past this.

00:11:34.760 --> 00:11:37.540
And I really feel that we're going to be
able to build a better classifier here

00:11:37.540 --> 00:11:37.850
in a minute.

