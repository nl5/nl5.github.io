WEBVTT
Kind: captions
Language: zh-CN

00:00:00.350 --> 00:00:00.990
好 那我们开始吧

00:00:00.990 --> 00:00:03.649
估计你已经试着验证了一下这个理论

00:00:03.649 --> 00:00:03.650
也就是 词语对标签具有预测性

00:00:03.650 --> 00:00:06.669
也就是 词语对标签具有预测性

00:00:06.669 --> 00:00:09.289
现在 我向大家展示一下 我是怎么解决这个问题的

00:00:09.289 --> 00:00:11.359
我们可以比较一下笔记

00:00:11.359 --> 00:00:12.639
我非常喜欢这种学习方式

00:00:12.640 --> 00:00:14.830
因为 我认为 这是最有用的

00:00:14.830 --> 00:00:20.160
人们先在脑海中构思解决问题的思路 然后思考

00:00:20.160 --> 00:00:24.989
用哪些工具来解决问题 最后再看看别人是如何解决问题的

00:00:24.989 --> 00:00:24.990
我认为 这种方式可以学到很多 也是很好的教学方式

00:00:24.990 --> 00:00:29.820
我认为 这种方式可以学到很多 也是很好的教学方式

00:00:29.820 --> 00:00:34.429
知道你真正的程度水平 看看你如何真正地解决问题

00:00:34.429 --> 00:00:37.019
像在实战中一样 而不是像在课堂上去解决问题

00:00:37.020 --> 00:00:40.600
然后把自己的方案与别人的做对比

00:00:40.600 --> 00:00:43.310
好 我们就来解决这个问题吧

00:00:43.310 --> 00:00:47.460
我这里有一组实用的工具

00:00:47.460 --> 00:00:48.539
我总是会从 collections 中导入 Counter

00:00:48.539 --> 00:00:50.539
所以 我们稍后要数词数

00:00:50.539 --> 00:00:53.405
而且我发现 Counter 与字典相比

00:00:53.405 --> 00:00:55.512
用起来更快更方便

00:00:55.512 --> 00:00:57.320
我会向大家展示 如何使用它

00:00:57.320 --> 00:01:00.539
然后导入 numpy 用于我们的值计算

00:01:00.539 --> 00:01:05.789
所以 我们要做的第一件事 就是要数数

00:01:05.790 --> 00:01:07.602
给每个词出现的次数计数

00:01:07.602 --> 00:01:10.750
在各种正面和负面评价中出现多少次

00:01:10.750 --> 00:01:19.444
所以 for i range(len(reviews)) ...

00:01:19.444 --> 00:01:20.969
哦 忘了创建计数器

00:01:20.969 --> 00:01:25.326
所以 positive_counts = Counter()

00:01:25.326 --> 00:01:26.129
这是 Counter 对象的创建方式

00:01:26.129 --> 00:01:29.929
你先创建一个空的计数器 它有点像字典

00:01:29.930 --> 00:01:33.189
我们还要创建一个总计数器 total_counts 它是缓存的

00:01:33.189 --> 00:01:33.190
你可以使用其他值来创建它

00:01:33.190 --> 00:01:37.006
你可以使用其他值来创建它

00:01:37.006 --> 00:01:38.808
好了

00:01:38.808 --> 00:01:40.000
它运行起来像字典

00:01:40.000 --> 00:01:41.900
但你不需要真正创建原始的 keys

00:01:41.900 --> 00:01:44.489
你可以直接开始递增计数

00:01:44.489 --> 00:01:44.490
就好像你已经把所有的 key 已经输入好了

00:01:44.490 --> 00:01:46.769
就好像你已经把所有的 key 已经输入好了

00:01:46.769 --> 00:01:50.039
一会你就会明白我的意思

00:01:50.040 --> 00:01:52.056
所以 for i in range(len(reviews))

00:01:52.055 --> 00:01:58.481
对于每个评论和标签 如果第 i 个标签是“正面的”标签

00:02:00.147 --> 00:02:05.594
然后 我们就简单把该条评论中出现的所有词语出现次数统计一下

00:02:05.594 --> 00:02:08.919
将它们添加到 positive_counts 中

00:02:08.919 --> 00:02:11.597
所以 for word in reviews[i].split(' ')

00:02:15.740 --> 00:02:20.266
positive_counts[word] += 1

00:02:20.265 --> 00:02:24.021
total_counts[word] += 1

00:02:24.021 --> 00:02:26.554
else:

00:02:29.411 --> 00:02:31.289
做同样的操作

00:02:31.289 --> 00:02:36.840
同样的针对 negative_counts 和 total_counts 再写一遍

00:02:36.840 --> 00:02:37.780
好 我们检查一下

00:02:37.780 --> 00:02:38.498
所以 来运行一下

00:02:39.599 --> 00:02:42.150
需要花点时间跑 因为有 25000 条评论

00:02:42.150 --> 00:02:43.969
下一步要做的 就是观察一下数据

00:02:43.969 --> 00:02:47.150
所以 Counter 里有一个很方便的函数

00:02:47.150 --> 00:02:50.650
输入 positive_counts.most_common() 然后运行

00:02:50.650 --> 00:02:53.229
好了 不管你哪里计数的词语

00:02:53.229 --> 00:02:53.230
这些就是最常见的那些词汇

00:02:53.230 --> 00:02:54.729
这些就是最常见的那些词汇

00:02:54.729 --> 00:02:59.619
它没有真正告诉我 这些词都可以预测“正面”标签

00:02:59.620 --> 00:03:02.340
它只是告诉我 这些事最高频出现的词汇

00:03:02.340 --> 00:03:04.159
所以 我们现在要做的 就是数据标准化

00:03:04.159 --> 00:03:08.299
我们并不对哪些词汇最常见感兴趣

00:03:08.300 --> 00:03:10.699
我们感兴趣的是

00:03:10.699 --> 00:03:10.700
正面评价中出现多、负面评价中出现少的那些 对吧

00:03:10.700 --> 00:03:12.437
正面评价中出现多、负面评价中出现少的那些 对吧

00:03:12.437 --> 00:03:18.060
因为如果看看负面计数排行榜 也同样是这些词 对吧？

00:03:18.061 --> 00:03:22.400
因此 我们需要某种比值 让值更具可比性

00:03:22.400 --> 00:03:26.759
可以将两个列表作对比 而不是两张表单独观察来看

00:03:26.759 --> 00:03:26.760
所以 为了快一点 我告诉大家我是怎么计算

00:03:26.760 --> 00:03:29.729
所以 为了快一点 我告诉大家我是怎么计算

00:03:29.729 --> 00:03:34.149
这个比例的 我也把它放入了 counter 中

00:03:34.150 --> 00:03:37.409
如果我们看看正面/负面比

00:03:37.409 --> 00:03:40.299
正负比最高的词汇 大概长这样

00:03:40.300 --> 00:03:43.099
似乎看出一些端倪了

00:03:43.099 --> 00:03:43.100
这些大多是名字

00:03:43.100 --> 00:03:45.180
这些大多是名字

00:03:45.180 --> 00:03:47.550
所以 我猜测 这些是电影评论 对吧？

00:03:47.550 --> 00:03:52.569
所以 人们有一些最喜爱的演员 他们喜欢积极正面地谈论他们

00:03:52.569 --> 00:03:52.570
所以 如果你和明星演员有同样的姓

00:03:52.570 --> 00:03:55.359
所以 如果你和明星演员有同样的姓

00:03:55.360 --> 00:03:57.400
比如 Caruso, Gino 之类的 你也赚到了 对吧？

00:03:57.400 --> 00:04:01.360
我猜想 这些都是不太受欢迎的演员

00:04:01.360 --> 00:04:05.250
但我猜测 我关于词汇相关性的理论是正确的

00:04:05.250 --> 00:04:08.318
所以 这也不一定是正确的

00:04:08.318 --> 00:04:13.060
但是 如果该演员名字只被提到一次 或至少十次

00:04:13.060 --> 00:04:16.910
如果只在一个正面评价中出现过 它可能会出现在这个列表里

00:04:16.910 --> 00:04:20.519
当我们寻找相关性时 我们想要寻找的

00:04:20.519 --> 00:04:22.660
是某种经常出现的词汇 或者与某些地方有相关性

00:04:22.660 --> 00:04:25.279
如果某人只提到过一次 那么它 100% 将是正面的

00:04:25.279 --> 00:04:25.280
但这不是一个很具代表性的正面标签的特点

00:04:25.280 --> 00:04:29.029
但这不是一个很具代表性的正面标签的特点

00:04:29.029 --> 00:04:31.000
所以 我们把这个值 (出现次数) 调到 50 以上再看看

00:04:31.000 --> 00:04:33.029
看到了一堆名字… 哦 "excellently"

00:04:35.529 --> 00:04:36.089
很有意思

00:04:36.089 --> 00:04:37.529
还有这个词 "delightfully" 好

00:04:37.529 --> 00:04:40.469
我们再把它调高一点

00:04:40.470 --> 00:04:42.799
正如大家所看到的 我在调查数据

00:04:42.798 --> 00:04:45.286
我在进行观察 寻找模式

00:04:45.286 --> 00:04:49.506
改进我观察的方式 对词汇模式找到一种直观感觉

00:04:49.505 --> 00:04:51.008
哇哦 我看出苗头了

00:04:51.009 --> 00:04:54.610
我看到了一些词汇 flawless, superbly, perfection, astaire, captures...

00:04:54.610 --> 00:04:55.186
太棒了

00:04:55.185 --> 00:04:58.526
好了 我终于看到 我想找的一些正面标签的词汇了

00:04:58.526 --> 00:05:01.771
那些能够预测正面标签的词汇

00:05:01.771 --> 00:05:06.250
我们再来看看 如果找一些负面词汇 会有哪些词？

00:05:06.250 --> 00:05:09.810
pointless, atrocious, drivel, laughable, awful

00:05:09.810 --> 00:05:10.620
OK 太好了

00:05:10.620 --> 00:05:14.079
所以 现在 我认为我的理论相当不错

00:05:14.079 --> 00:05:18.079
我期望那些具有预测性的词明显具有预测性

00:05:18.079 --> 00:05:21.949
或者至少具有一定的相关性

00:05:21.949 --> 00:05:25.839
与那些我认为应该有关联的标签具有相关性

00:05:25.839 --> 00:05:29.389
所以 在下一节 我们将探讨

00:05:29.389 --> 00:05:33.149
我们如何利用这一预测理论 创建输入和输出数据

00:05:33.149 --> 00:05:36.899
让我们的网络将这种相关力转化为一个分类器

00:05:36.899 --> 00:05:37.269
好吧？

00:05:37.269 --> 00:05:40.889
请继续关注下一节 一会见

